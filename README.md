# Interpretable ML for Robotic Choreography Evaluation

This repository contains all code, data and results for our threeâ€part study on predicting and explaining audience evaluations of humanoidâ€robot choreographies:

1. **Classification** â€“ Bin-arize audience scores (1â€“3 â†’ 0, 4â€“5 â†’ 1) and train four model families (Logistic Regression, Random Forest, XGBoost, CatBoost) to predict â€œhigh vs. lowâ€ ratings across seven targets.  
2. **Regression** â€“ Predict the original 1â€“5 Likert scores with linear (Ridge) and tree-based regressors.  
3. **SHAP** â€“ Interpret the final models using a four-phase pipeline of SHAP value computation, dependence and interaction plots, stability analysis, subgroup analyses and decision plots.

---

## ðŸ“‚ Classification

**Folder:** `classification/`

### Sub-folders

- **`catboost_info/`**  
  Contains CatBoost training logs, feature importances and class-weight settings.
- **`classification_models_data/`**  
  Joblib-serialized pipelines, hyperparameter grids and saved model objects for each target.
- **`saved_overall_best_models/`**  
  The final chosen models (XGBoost & CatBoost) serialized via joblib for deployment.
- **`saved_tuned_models/`**  
  All grid-search results and best estimators (joblib format) before final selection.
---

## ðŸ“‚ Regression
**Folder:** `regression/`

### Sub-folders

- **`Best Model per Target/`**  
The final chosen models (XGBoost & CatBoost serialized via JSON and CBM, respectively) for deployment.
- **`Tuned Models/`**  
All grid-search results, best estimators, and background datasets related to each model before the final selection.

**Folder:** `data/`

### Sub-folders

- **`regression > Data Splits/`**  
Pipelines, hyperparameter grids, and saved model objects for each target.

---

## ðŸ“‚ SHAP

**Folder:** `Shap/`

### Sub-folders

These folders contain the outputs generated by the [`shap_analysis.ipynb`](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/shap_analysis.ipynb) notebook. Because there are many files, we group them into subfolders to make it easier to find and view each result.

- **[Prototypical Decision Plots/](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/tree/main/shap/Prototypical%20Decision%20Plots)**  
  Contains the Prototypical Decision Plots.
- **[SHAP dependence plots â€“ PDP & ICE plots/](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/tree/main/shap/SHAP%20dependence%20plots%20-%20PDP%20%26%20ICE%20plots)**  
  Contains:
  - Partial Dependence & ICE plots 
  - SHAP dependence plots
  - SHAP summary plots

- **[results/](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/tree/main/shap/results)**  
  Contains all raw outputs produced by the [`shap_analysis.ipynb`](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/shap_analysis.ipynb) notebook.

### Files

- **[final_summary.csv](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/final_summary.csv)**  
  The master summary table referenced in the report.

- **[report_snippets.md](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/report_snippets.md)**  
  The markdown file containing report excerpts used in the report.

- **[settings.yaml](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/settings.yaml)**  
  The configuration file required to run [`shap_analysis.ipynb`](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/shap_analysis.ipynb). It defines every variable the notebook uses and can be edited to produce different results.

- **[shap_analysis.ipynb](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/shap_analysis.ipynb)**  
  The main Jupyter notebook implementing the full four-phase SHAP analysis pipeline.

---

## ðŸ“‚ Data

> **Note:** You will find both pre-processed (cleaned) and post-processed (split, encoded) versions organized under `data/` so you can reproduce each ML pipeline exactly.

