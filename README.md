# Interpretable ML for Robotic Choreography Evaluation

This repository contains the complete code, data, and results for a study on predicting and explaining audience evaluations of humanoid-robot choreographies. The core objective is to build an automated system for evaluating robot performances and, more importantly, to understand the key factors that drive audience perception.

The final, comprehensive report detailing our methodology and findings is available in **[`report.pdf`](./report.pdf)**.

This project is structured as a three-part machine learning pipeline:

1.  **Classification** â€“ Predict whether a choreography receives a "high" or "low" rating. Audience scores (1-5) are binarized (1â€“3 â†’ 0, 4â€“5 â†’ 1), and four model families (Logistic Regression, Random Forest, XGBoost, CatBoost) are trained on seven distinct evaluation targets.
2.  **Regression** â€“ Predict the original 1â€“5 Likert scores using linear (Ridge) and tree-based regressors to capture more nuanced evaluations.
3.  **SHAP (SHapley Additive exPlanations)** â€“ Interpret the final models using a comprehensive SHAP analysis to identify which choreography features most influence audience scores.

---
## ðŸ“‚ EDA
-   **[`eda_and_preprocessing.ipynb`](./eda_and_preprocessing.ipynb)**: A Jupyter notebook that:
    -   Loads the raw data.
    -   Cleans and preprocesses features (e.g., standardizing text, handling duplicates).
    -   Performs one-hot encoding for the `musicGenre` column.
    -   Conducts EDA with visualizations to explore the data.

## ðŸ“‚ Classification

**Folder:** `classification/`

-   **[`tabular_quickstart.ipynb`](./classification/tabular_quickstart.ipynb)**: An initial exploration using AutoML to establish a strong performance baseline and gain insights before manual model development.

-   **[`classifier.ipynb`](./classification/classifier.ipynb)**: The primary notebook for the classification task. It implements the end-to-end pipeline:
    1.  Data loading and splitting for each of the seven targets.
    2.  Hyperparameter tuning using GridSearchCV for four model families: Logistic Regression, Random Forest, XGBoost, and CatBoost.
    3.  Model evaluation using metrics like Accuracy, F1-Score, and AUC.
    4.  Saving all tuned models and the final, best-performing model for each target

### Sub-folders

- **`catboost_info/`**  
  Contains CatBoost training logs, feature importances and class-weight settings.
- **`classification_models_data/`**  
  Joblib-serialized pipelines, hyperparameter grids and saved model objects for each target.
- **`saved_overall_best_models/`**  
  The final chosen models (XGBoost & CatBoost) serialized via joblib for deployment.
- **`saved_tuned_models/`**  
  All grid-search results and best estimators (joblib format) before final selection.
---

## ðŸ“‚ Regression
**Folder:** `regression/`

### Sub-folders

- **`Best Model per Target/`**  
The final chosen models (XGBoost & CatBoost serialized via JSON and CBM, respectively) for deployment.
- **`Tuned Models/`**  
All grid-search results, best estimators, and background datasets related to each model before the final selection.

**Folder:** `data/`

### Sub-folders

- **`regression/ Data Splits/`**  
Pipelines, hyperparameter grids, and saved model objects for each target.

---

## ðŸ“‚ SHAP

**Folder:** `Shap/`

### Sub-folders

These folders contain the outputs generated by the [`shap_analysis.ipynb`](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/shap_analysis.ipynb) notebook. Because there are many files, we group them into subfolders to make it easier to find and view each result.

- **[Prototypical Decision Plots/](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/tree/main/shap/Prototypical%20Decision%20Plots)**  
  Contains the Prototypical Decision Plots.
- **[SHAP dependence plots â€“ PDP & ICE plots/](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/tree/main/shap/SHAP%20dependence%20plots%20-%20PDP%20%26%20ICE%20plots)**  
  Contains:
  - Partial Dependence & ICE plots 
  - SHAP dependence plots
  - SHAP summary plots

- **[results/](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/tree/main/shap/results)**  
  Contains all raw outputs produced by the [`shap_analysis.ipynb`](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/shap_analysis.ipynb) notebook.

### Files

- **[final_summary.csv](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/final_summary.csv)**  
  The master summary table referenced in the report.

- **[report_snippets.md](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/report_snippets.md)**  
  The markdown file containing report excerpts used in the report.

- **[settings.yaml](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/settings.yaml)**  
  The configuration file required to run [`shap_analysis.ipynb`](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/shap_analysis.ipynb). It defines every variable the notebook uses and can be edited to produce different results.

- **[shap_analysis.ipynb](https://github.com/rzsoli/Evaluations_on_Robotic_Choreographies/blob/main/shap/shap_analysis.ipynb)**  
  The main Jupyter notebook implementing the full four-phase SHAP analysis pipeline.

---

## ðŸ“‚ Data

> **Note:** You will find both pre-processed (cleaned) and post-processed (split, encoded) versions organized under `data/` so you can reproduce each ML pipeline exactly.

