{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW5lP_QqddKU",
        "outputId": "1742de31-be49-4360-c0a3-bb558c6d731a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdGxeX0xAT30"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('GITHUB_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NsgrMUPcy8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b242266-4f44-406d-a2eb-731547de7eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Evaluations_on_Robotic_Choreographies'...\n",
            "remote: Enumerating objects: 716, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 716 (delta 57), reused 8 (delta 8), pack-reused 561 (from 2)\u001b[K\n",
            "Receiving objects: 100% (716/716), 62.59 MiB | 8.62 MiB/s, done.\n",
            "Resolving deltas: 100% (291/291), done.\n",
            "Updating files: 100% (357/357), done.\n"
          ]
        }
      ],
      "source": [
        "# Replace YOUR_USERNAME and YOUR_TOKEN with your actual GitHub username and token.\n",
        "from getpass import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "!git clone https://{userdata.get('GITHUB_TOKEN')}@github.com/rzsoli/Evaluations_on_Robotic_Choreographies.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRsqRhkYU-Fw"
      },
      "source": [
        "# SHAP Analysis for Classification and Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcXtrzReU-Fz"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import KNNImputer\n",
        "# Add any other specific model classes if they appear as 'best models' later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D4yi6-bU-F0"
      },
      "source": [
        "## Classification SHAP Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkNLsmNAU-F0"
      },
      "outputs": [],
      "source": [
        "classification_target_names = [\n",
        "    \"HumanCharacterization\",\n",
        "    \"HumanReproducibility\",\n",
        "    \"MovementTechnique\",\n",
        "    \"PublicInvolvement\",\n",
        "    \"Rhythm\",\n",
        "    \"SpaceUse\",\n",
        "    \"StoryTelling\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qAysrUqXmQbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "phase1"
      ],
      "metadata": {
        "id": "idy2fKqhmS-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap\n",
        "import yaml\n",
        "import logging\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\".*please export the model by calling `Booster.save_model`.*\")\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Load settings\n",
        "with open('settings.yaml') as f:\n",
        "    settings = yaml.safe_load(f)\n",
        "\n",
        "RND = settings.get('random_seed', 42)\n",
        "MODEL_DIR = \"/content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/\"\n",
        "DATA_DIR = \"/content/Evaluations_on_Robotic_Choreographies/classification/classification_models_data/\"\n",
        "OUTPUT_DIR = \"/content/Evaluations_on_Robotic_Choreographies/shap/classification/\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def get_targets(dirpath):\n",
        "    return [d.replace('EvaluationChoreography', '')\n",
        "            for d in os.listdir(dirpath)\n",
        "            if d.startswith('EvaluationChoreography')]\n",
        "\n",
        "def unwrap_pipeline(model):\n",
        "    preproc = None\n",
        "    actual = model\n",
        "    if isinstance(model, Pipeline):\n",
        "        actual = model.steps[-1][1]\n",
        "        if len(model.steps) > 1:\n",
        "            preproc = Pipeline(model.steps[:-1])\n",
        "    return actual, preproc\n",
        "\n",
        "for target in get_targets(DATA_DIR):\n",
        "    logger.info(f\"Starting Phase1 for target: {target}\")\n",
        "    try:\n",
        "        # Paths\n",
        "        subdir = os.path.join(DATA_DIR, f\"EvaluationChoreography{target}\")\n",
        "        train_path = os.path.join(subdir, \"X_train.csv\")\n",
        "        hold_path = os.path.join(subdir, \"X_holdout.csv\")\n",
        "        y_path = os.path.join(subdir, \"y_train.csv\")\n",
        "        if not all(os.path.exists(p) for p in (train_path, hold_path, y_path)):\n",
        "            logger.error(f\"Missing data files for {target}, skipping Phase1.\")\n",
        "            continue\n",
        "        X_train = pd.read_csv(train_path)\n",
        "        # Assuming y_train is the first (and likely only) column in y_train.csv\n",
        "        y_train = pd.read_csv(y_path).iloc[:, 0]\n",
        "        X_hold = pd.read_csv(hold_path)\n",
        "\n",
        "        # Load model\n",
        "        model_file = next((f for f in os.listdir(MODEL_DIR)\n",
        "                           if target in f and f.startswith(('OVERALL_BEST_XGBoost_GridCV','OVERALL_BEST_CatBoost_GridCV'))), None)\n",
        "        if not model_file:\n",
        "            logger.warning(f\"No model found for {target}, skipping.\")\n",
        "            continue\n",
        "        model = joblib.load(os.path.join(MODEL_DIR, model_file))\n",
        "\n",
        "        # Unwrap pipeline\n",
        "        actual_model, preproc = unwrap_pipeline(model)\n",
        "\n",
        "        # Determine and save feature names\n",
        "        if preproc:\n",
        "            try:\n",
        "                feat_names = preproc.get_feature_names_out(X_train.columns)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"get_feature_names_out failed for {target}: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            feat_names = X_train.columns.tolist()\n",
        "        out_dir = os.path.join(OUTPUT_DIR, target)\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        fn_path = os.path.join(out_dir, f\"feature_names_{target}.txt\")\n",
        "        pd.Series(feat_names).to_csv(fn_path, index=False, header=False)\n",
        "        assert os.path.exists(fn_path), \"Feature names file not saved\"\n",
        "\n",
        "        # Preprocess data\n",
        "        def apply_proc(df):\n",
        "            if preproc:\n",
        "                arr = preproc.transform(df)\n",
        "                return pd.DataFrame(arr, columns=feat_names, index=df.index)\n",
        "            return df.copy()\n",
        "        X_train_p = apply_proc(X_train)\n",
        "        X_hold_p = apply_proc(X_hold)\n",
        "\n",
        "        # Background sampling\n",
        "        bcfg = settings['background']\n",
        "        desired = bcfg['sample_size']\n",
        "        actual_n = min(desired, len(X_train_p))\n",
        "        actual_n = max(actual_n, bcfg['min_size'])\n",
        "\n",
        "        # --- Handle single-class y_train for stratification ---\n",
        "        if bcfg['stratify']:\n",
        "            if y_train.nunique() < 2:\n",
        "                logger.warning(f\"Skipping stratification for {target}: y_train has only one unique class. Falling back to random sampling.\")\n",
        "                background = X_train_p.sample(actual_n, random_state=RND)\n",
        "            elif len(y_train) < actual_n: # Ensure enough samples for stratification based on actual_n\n",
        "                 logger.warning(f\"Not enough samples in y_train ({len(y_train)}) for desired background size ({actual_n}) with stratification for {target}. Falling back to random sampling.\")\n",
        "                 background = X_train_p.sample(actual_n, random_state=RND)\n",
        "            else:\n",
        "                sss = StratifiedShuffleSplit(n_splits=1, train_size=actual_n, random_state=RND)\n",
        "                idx, _ = next(sss.split(X_train_p, y_train))\n",
        "                background = X_train_p.iloc[idx]\n",
        "        else: # If stratification is explicitly turned off in settings\n",
        "            background = X_train_p.sample(actual_n, random_state=RND)\n",
        "\n",
        "        bg_path = os.path.join(out_dir, 'background.csv')\n",
        "        background.to_csv(bg_path, index=False)\n",
        "        assert os.path.exists(bg_path) and len(background) >= bcfg['min_size'], \"Background sample invalid\"\n",
        "\n",
        "        # Instantiate explainer\n",
        "        if isinstance(actual_model, (XGBClassifier, CatBoostClassifier)):\n",
        "            explainer = shap.TreeExplainer(actual_model, background)\n",
        "        else:\n",
        "            explainer = shap.KernelExplainer(actual_model.predict_proba, background)\n",
        "        ev = np.atleast_1d(explainer.expected_value)\n",
        "        logger.info(f\"Explainer expected_value shape for {target}: {ev.shape}\")\n",
        "\n",
        "        # Compute raw SHAP values\n",
        "        raw = explainer.shap_values(X_hold_p)\n",
        "        shap_vals = raw[1] if isinstance(raw, list) and len(raw) >= 2 else np.array(raw)\n",
        "        assert shap_vals.shape == X_hold_p.shape, f\"SHAP shape mismatch: {shap_vals.shape} vs {X_hold_p.shape}\"\n",
        "        raw_path = os.path.join(out_dir, f\"raw_{target}.npy\")\n",
        "        np.save(raw_path, shap_vals)\n",
        "        assert os.path.exists(raw_path), \"Raw SHAP file not saved\"\n",
        "\n",
        "        # Save baseline\n",
        "        baseline = ev[1] if ev.size >= 2 else ev[0]\n",
        "        base_path = os.path.join(out_dir, 'baseline.txt')\n",
        "        with open(base_path, 'w') as f:\n",
        "            f.write(str(baseline))\n",
        "        assert os.path.exists(base_path), \"Baseline file not saved\"\n",
        "\n",
        "        # Compute interactions (Tree only)\n",
        "        # int_path needs to be defined for config even if interactions are skipped\n",
        "        int_path = None\n",
        "        if isinstance(explainer, shap.TreeExplainer):\n",
        "            topn = settings['interaction']['top_n_features']\n",
        "            subsz = settings['interaction']['subsample_size']\n",
        "            # select top features\n",
        "            means = np.abs(shap_vals).mean(axis=0)\n",
        "            idx = np.argsort(means)[-topn:][::-1]\n",
        "            subset = X_hold_p.iloc[:, idx]\n",
        "            # subsample rows\n",
        "            n_rows = min(subsz, len(subset))\n",
        "            subp = subset.sample(n_rows, random_state=RND)\n",
        "            inter_vals = explainer.shap_interaction_values(subp)\n",
        "            int_path = os.path.join(out_dir, 'interaction.npy')\n",
        "            np.save(int_path, inter_vals)\n",
        "            assert os.path.exists(int_path), \"Interaction file not saved\"\n",
        "        else:\n",
        "            logger.warning(f\"Skipping interactions for {target}: not a TreeExplainer.\")\n",
        "\n",
        "        # Persist config & validate\n",
        "        cfg = {\n",
        "            'model_path': os.path.join(MODEL_DIR, model_file),\n",
        "            'background_path': bg_path,\n",
        "            'eval_data_path': hold_path,\n",
        "            'feature_names_path': fn_path,\n",
        "            'raw_shap_path': raw_path,\n",
        "            'baseline_path': base_path,\n",
        "            'interaction_path': int_path, # Now int_path is always defined\n",
        "            'explainer_type': type(explainer).__name__,\n",
        "            'explainer_params': {\n",
        "                'feature_perturbation': getattr(explainer, 'feature_perturbation', None),\n",
        "                'nsamples': getattr(explainer, 'nsamples', None)\n",
        "            }\n",
        "        }\n",
        "        cfg_path = os.path.join(out_dir, 'config.json')\n",
        "        with open(cfg_path, 'w') as f:\n",
        "            json.dump(cfg, f, indent=2)\n",
        "        # validate all paths\n",
        "        for key, p in cfg.items():\n",
        "            if key.endswith('_path') and p: # Only check if path is not None\n",
        "                assert os.path.exists(p), f\"Config path missing: {key}\"\n",
        "\n",
        "        logger.info(f\"Phase1 complete for {target}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in Phase1 for {target}: {e}\")\n",
        "        continue\n",
        "\n",
        "logger.info(\"All classification Phase1 done.\")\n",
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap\n",
        "import yaml\n",
        "import logging\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Optional: enable if using NN models\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "except ImportError:\n",
        "    tf = None\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    force=True\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Load settings\n",
        "with open('/content/settings.yaml') as f:\n",
        "    settings = yaml.safe_load(f)\n",
        "\n",
        "RND = settings.get('random_seed', 42)\n",
        "PROJECT_ROOT = \"/content/Evaluations_on_Robotic_Choreographies/\"\n",
        "\n",
        "# --- MODIFICATION START ---\n",
        "# Path for datasets remains the same.\n",
        "DATA_DIR = os.path.join(PROJECT_ROOT, 'data', 'regression')\n",
        "# New path for loading the tuned regression models.\n",
        "MODEL_DIR_REG = os.path.join(PROJECT_ROOT, 'regression', 'Tuned Models')\n",
        "# --- MODIFICATION END ---\n",
        "\n",
        "SHAP_OUT = os.path.join(PROJECT_ROOT, 'shap', 'regression')\n",
        "os.makedirs(SHAP_OUT, exist_ok=True)\n",
        "\n",
        "# Dictionary to map specific targets to specific regression methods\n",
        "TARGET_METHOD_MAP = {\n",
        "    \"Storytelling\": \"XGBoost\",\n",
        "    \"SpaceUse\": \"XGBoost\",\n",
        "    \"Rhythm\": \"CatBoost\",\n",
        "    \"PublicInvolvement\": \"XGBoost\",\n",
        "    \"MovementTechnique\": \"XGBoost\",\n",
        "    \"HumanReproducibility\": \"XGBoost\",\n",
        "    \"HumanCharacterization\": \"CatBoost\"\n",
        "}\n",
        "\n",
        "# Utility: unwrap pipelines\n",
        "def unwrap_pipeline(model):\n",
        "    preproc = None\n",
        "    actual = model\n",
        "    if isinstance(model, Pipeline):\n",
        "        actual = model.steps[-1][1]\n",
        "        if len(model.steps) > 1:\n",
        "            preproc = Pipeline(model.steps[:-1])\n",
        "    return actual, preproc\n",
        "\n",
        "# Utility: apply preprocessing and enforce feature names\n",
        "def apply_preproc(df, preproc, feat_names):\n",
        "    if preproc:\n",
        "        arr = preproc.transform(df)\n",
        "        return pd.DataFrame(arr, columns=feat_names, index=df.index)\n",
        "    else:\n",
        "        return df.copy()\n",
        "\n",
        "# Utility: top-N features by mean abs shap\n",
        "def get_top_n_features(shap_vals, feat_names, n=10):\n",
        "    means = np.abs(shap_vals).mean(axis=0)\n",
        "    idx = np.argsort(means)[-n:][::-1]\n",
        "    return [feat_names[i] for i in idx]\n",
        "\n",
        "# Main Phase1 loop\n",
        "def run_regression_phase1():\n",
        "    # Iterate through the target-method mapping\n",
        "    for target, method in TARGET_METHOD_MAP.items():\n",
        "        logger.info(f\"Starting Phase1 for {method}/{target}\")\n",
        "        try:\n",
        "            # Paths for train/test (Uses DATA_DIR - UNCHANGED)\n",
        "            low = target.lower()\n",
        "            train_path = os.path.join(DATA_DIR, 'Data Splits', target, f'X_train_{low}.csv')\n",
        "            test_path  = os.path.join(DATA_DIR, 'Data Splits', target, f'X_test_{low}.csv')\n",
        "            if not os.path.exists(train_path) or not os.path.exists(test_path):\n",
        "                logger.warning(f\"Missing train or test for {target}, skipping.\")\n",
        "                continue\n",
        "            X_train = pd.read_csv(train_path)\n",
        "            X_test  = pd.read_csv(test_path)\n",
        "\n",
        "            # Load model and optional scaler (Uses MODEL_DIR_REG - CHANGED)\n",
        "            model = None\n",
        "            pipeline_pre = None\n",
        "            model_path = None\n",
        "            if method == \"CatBoost\" and CatBoostRegressor is not None:\n",
        "                model_path = os.path.join(MODEL_DIR_REG, 'CatBoost', f'catboost_{low}.cbm')\n",
        "                if os.path.exists(model_path):\n",
        "                    model = CatBoostRegressor()\n",
        "                    model.load_model(model_path)\n",
        "            elif method == \"XGBoost\" and XGBRegressor is not None:\n",
        "                model_path = os.path.join(MODEL_DIR_REG, 'XGBoost', f'xgb_model_{low}.json')\n",
        "                if os.path.exists(model_path):\n",
        "                    model = XGBRegressor()\n",
        "                    model.load_model(model_path)\n",
        "            elif method == \"Ridge Pipeline\":\n",
        "                model_path = os.path.join(MODEL_DIR_REG, 'Ridge Pipeline', f'ridge_pipeline_{low}.pkl')\n",
        "                if os.path.exists(model_path):\n",
        "                    model = joblib.load(model_path)\n",
        "            elif method == \"NN Model\" and tf is not None:\n",
        "                mpath = os.path.join(MODEL_DIR_REG, 'NN Model', f'mlp_best_{low}.keras')\n",
        "                spath = os.path.join(MODEL_DIR_REG, 'NN Model', f'scaler_{low}.pkl')\n",
        "                if os.path.exists(mpath) and os.path.exists(spath):\n",
        "                    model = tf.keras.models.load_model(mpath, compile=False)\n",
        "                    pipeline_pre = joblib.load(spath)\n",
        "                model_path = mpath\n",
        "\n",
        "            if model is None:\n",
        "                logger.warning(f\"Model file not found for {method}/{target}, skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Unwrap any sklearn Pipeline\n",
        "            actual_model, preproc = unwrap_pipeline(model)\n",
        "            # Override for NN\n",
        "            if method == \"NN Model\":\n",
        "                preproc = pipeline_pre\n",
        "\n",
        "            # Determine feature names\n",
        "            if preproc is not None:\n",
        "                try:\n",
        "                    feat_names = preproc.get_feature_names_out(X_train.columns)\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"get_feature_names_out failed for {method}/{target}: {e}\")\n",
        "                    raise\n",
        "            else:\n",
        "                feat_names = X_train.columns.tolist()\n",
        "\n",
        "            # Save feature names to the new directory structure\n",
        "            out_dir = os.path.join(SHAP_OUT, \"result\", target)\n",
        "            os.makedirs(out_dir, exist_ok=True)\n",
        "            fn_path = os.path.join(out_dir, f'feature_names_{target}.txt')\n",
        "            pd.Series(feat_names).to_csv(fn_path, index=False, header=False)\n",
        "\n",
        "            # Preprocess datasets\n",
        "            X_train_p = apply_preproc(X_train, preproc, feat_names)\n",
        "            X_test_p  = apply_preproc(X_test,  preproc, feat_names)\n",
        "\n",
        "            # Background sampling (regression random)\n",
        "            bcfg = settings['background']\n",
        "            desired = bcfg['sample_size']\n",
        "            actual_n = min(desired, len(X_train_p))\n",
        "            actual_n = max(actual_n, bcfg['min_size'])\n",
        "            background = X_train_p.sample(actual_n, random_state=RND)\n",
        "            bg_path = os.path.join(out_dir, 'background.csv')\n",
        "            background.to_csv(bg_path, index=False)\n",
        "\n",
        "            # Instantiate SHAP explainer\n",
        "            if isinstance(actual_model, (CatBoostRegressor, XGBRegressor)):\n",
        "                expl = shap.TreeExplainer(actual_model, background)\n",
        "            else:\n",
        "                expl = shap.KernelExplainer(actual_model.predict, background)\n",
        "            ev = np.atleast_1d(expl.expected_value)\n",
        "            logger.info(f\"Expected value shape for {method}/{target}: {ev.shape}\")\n",
        "\n",
        "            # Compute and save raw SHAP values\n",
        "            raw = expl.shap_values(X_test_p)\n",
        "            shap_vals = raw if not isinstance(raw, list) else raw[0] # For regression, shap_values returns array directly\n",
        "            raw_path = os.path.join(out_dir, f\"raw_{target}.npy\")\n",
        "            np.save(raw_path, shap_vals)\n",
        "\n",
        "            # Save baseline\n",
        "            baseline = ev[0] # For regression, expected_value is typically a single scalar\n",
        "            base_path = os.path.join(out_dir, 'baseline.txt')\n",
        "            with open(base_path, 'w') as f:\n",
        "                f.write(str(baseline))\n",
        "\n",
        "            # Compute interactions (Tree only) with subsample\n",
        "            if isinstance(expl, shap.TreeExplainer):\n",
        "                topn = settings['interaction']['top_n_features']\n",
        "                subsz = settings['interaction']['subsample_size']\n",
        "                feats = get_top_n_features(shap_vals, feat_names, n=topn)\n",
        "                subset = X_test_p[feats]\n",
        "                n_rows = min(subsz, len(subset))\n",
        "                subp = subset.sample(n_rows, random_state=RND)\n",
        "                iv = expl.shap_interaction_values(subp)\n",
        "                int_path = os.path.join(out_dir, 'interaction.npy')\n",
        "                np.save(int_path, iv)\n",
        "            else:\n",
        "                int_path = None # Ensure int_path is defined even if not used\n",
        "\n",
        "            # Persist config\n",
        "            cfg = {\n",
        "                'model_path': model_path,\n",
        "                'background_path': bg_path,\n",
        "                'eval_data_path': test_path,\n",
        "                'feature_names_path': fn_path,\n",
        "                'raw_shap_path': raw_path,\n",
        "                'baseline_path': base_path,\n",
        "                'interaction_path': int_path,\n",
        "                'explainer_type': type(expl).__name__,\n",
        "                'explainer_params': {\n",
        "                    'feature_perturbation': getattr(expl, 'feature_perturbation', None),\n",
        "                    'nsamples': getattr(expl, 'nsamples', None)\n",
        "                }\n",
        "            }\n",
        "            cfg_path = os.path.join(out_dir, 'config.json')\n",
        "            with open(cfg_path, 'w') as f:\n",
        "                json.dump(cfg, f, indent=2)\n",
        "            # Add assertion for config.json\n",
        "            assert os.path.exists(cfg_path), f\"Phase1 failed to write config.json for {method}/{target}\"\n",
        "\n",
        "            logger.info(f\"Phase1 complete for {method}/{target}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in Phase1 for {method}/{target}: {e}\")\n",
        "            continue\n",
        "\n",
        "    logger.info(\"All regression Phase1 done.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_regression_phase1()"
      ],
      "metadata": {
        "id": "BpRTPfaOmQBt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900e75e8-9d96-4d20-a568-10c2dd7e9d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:30:40] WARNING: /workspace/src/collective/../data/../common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
            "configuration generated by an older version of XGBoost, please export the model by calling\n",
            "`Booster.save_model` from that version first, then load it back in current version. See:\n",
            "\n",
            "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
            "\n",
            "for more details about differences between saving model and serializing.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "2025-07-06 20:31:10,773 [INFO] Starting Phase1 for XGBoost/Storytelling\n",
            "2025-07-06 20:31:10,952 [INFO] Expected value shape for XGBoost/Storytelling: (1,)\n",
            " 97%|=================== | 828/857 [00:17<00:00]       2025-07-06 20:31:27,760 [INFO] Phase1 complete for XGBoost/Storytelling\n",
            "2025-07-06 20:31:27,763 [INFO] Starting Phase1 for XGBoost/SpaceUse\n",
            "2025-07-06 20:31:27,865 [INFO] Expected value shape for XGBoost/SpaceUse: (1,)\n",
            "2025-07-06 20:31:29,459 [INFO] Phase1 complete for XGBoost/SpaceUse\n",
            "2025-07-06 20:31:29,460 [INFO] Starting Phase1 for CatBoost/Rhythm\n",
            "2025-07-06 20:31:29,514 [INFO] Expected value shape for CatBoost/Rhythm: (1,)\n",
            "2025-07-06 20:31:33,224 [INFO] Phase1 complete for CatBoost/Rhythm\n",
            "2025-07-06 20:31:33,225 [INFO] Starting Phase1 for XGBoost/PublicInvolvement\n",
            "2025-07-06 20:31:33,346 [INFO] Expected value shape for XGBoost/PublicInvolvement: (1,)\n",
            "2025-07-06 20:31:41,107 [INFO] Phase1 complete for XGBoost/PublicInvolvement\n",
            "2025-07-06 20:31:41,108 [INFO] Starting Phase1 for XGBoost/MovementTechnique\n",
            "2025-07-06 20:31:41,406 [INFO] Expected value shape for XGBoost/MovementTechnique: (1,)\n",
            " 95%|=================== | 810/857 [00:16<00:00]       2025-07-06 20:31:57,866 [INFO] Phase1 complete for XGBoost/MovementTechnique\n",
            "2025-07-06 20:31:57,867 [INFO] Starting Phase1 for XGBoost/HumanReproducibility\n",
            "2025-07-06 20:31:57,950 [INFO] Expected value shape for XGBoost/HumanReproducibility: (1,)\n",
            "2025-07-06 20:32:02,534 [INFO] Phase1 complete for XGBoost/HumanReproducibility\n",
            "2025-07-06 20:32:02,534 [INFO] Starting Phase1 for CatBoost/HumanCharacterization\n",
            "2025-07-06 20:32:02,595 [INFO] Expected value shape for CatBoost/HumanCharacterization: (1,)\n",
            "2025-07-06 20:32:08,737 [INFO] Phase1 complete for CatBoost/HumanCharacterization\n",
            "2025-07-06 20:32:08,738 [INFO] All regression Phase1 done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "newest and lets be final try on phase2"
      ],
      "metadata": {
        "id": "1edKtXVimbiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import yaml\n",
        "import logging\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap\n",
        "import matplotlib\n",
        "matplotlib.use('Agg') # Set the Matplotlib backend to 'Agg' for headless plot generation\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    force=True\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Load settings\n",
        "with open('settings.yaml') as f:\n",
        "    settings = yaml.safe_load(f)\n",
        "RND = settings.get('random_seed', 42)\n",
        "PROJECT_ROOT = \"/content/Evaluations_on_Robotic_Choreographies/\"\n",
        "SHAP_ROOT = os.path.join(PROJECT_ROOT, 'shap')\n",
        "\n",
        "# Helper: unwrap pipeline\n",
        "\n",
        "def unwrap_pipeline(model):\n",
        "    preproc = None\n",
        "    actual = model\n",
        "    if isinstance(model, Pipeline):\n",
        "        actual = model.steps[-1][1]\n",
        "        if len(model.steps) > 1:\n",
        "            preproc = Pipeline(model.steps[:-1])\n",
        "    return actual, preproc\n",
        "\n",
        "# Helper: apply preprocessing\n",
        "\n",
        "def apply_preproc(df, preproc, feat_names):\n",
        "    \"\"\"Applies preprocessing if a preproc pipeline is provided.\"\"\"\n",
        "    if preproc is not None:\n",
        "        # Ensure the preprocessor can handle DataFrame or convert to numpy array if needed\n",
        "        arr = preproc.transform(df)\n",
        "        return pd.DataFrame(arr, columns=feat_names, index=df.index)\n",
        "    # If no preprocessor, return a copy of the DataFrame, ensuring column names are set if feat_names is available\n",
        "    if feat_names is not None:\n",
        "        return pd.DataFrame(df.values, columns=feat_names, index=df.index)\n",
        "    return df.copy()\n",
        "\n",
        "# Helper: top-N features by mean abs shap\n",
        "\n",
        "def get_top_n_features(shap_vals, feat_names, n=10):\n",
        "    means = np.abs(shap_vals).mean(axis=0)\n",
        "    idx = np.argsort(means)[-n:][::-1]\n",
        "    return [feat_names[i] for i in idx]\n",
        "\n",
        "# Main Phase2\n",
        "for domain in ['classification', 'regression']:\n",
        "    base_dir = os.path.join(SHAP_ROOT, domain)\n",
        "    if domain == 'classification':\n",
        "           # This classification block remains unchanged.\n",
        "        # one folder per target\n",
        "        for target in os.listdir(base_dir):\n",
        "            out_dir = os.path.join(base_dir, target)\n",
        "            if not os.path.isdir(out_dir):\n",
        "                logger.info(f\"Skipping non-directory entry in classification: {out_dir}\")\n",
        "                continue\n",
        "            cfg_path = os.path.join(out_dir, 'config.json')\n",
        "            if not os.path.exists(cfg_path):\n",
        "                logger.warning(f\"Config file not found: {cfg_path}. Skipping {domain}/{target}.\")\n",
        "                continue\n",
        "            cfg = json.load(open(cfg_path))\n",
        "            model_path = cfg['model_path']\n",
        "            bg_path = cfg['background_path']\n",
        "            eval_path = cfg['eval_data_path']\n",
        "            fn_path = cfg['feature_names_path']\n",
        "            shap_path = cfg['raw_shap_path']\n",
        "            expl_type = cfg['explainer_type']\n",
        "            X_raw = pd.read_csv(eval_path)\n",
        "            feat_names = pd.read_csv(fn_path, header=None).iloc[:,0].tolist()\n",
        "            shap_vals = np.load(shap_path)\n",
        "            background = pd.read_csv(bg_path)\n",
        "            model = joblib.load(model_path)\n",
        "            actual_model, preproc = unwrap_pipeline(model)\n",
        "            X_proc = apply_preproc(X_raw, preproc, feat_names)\n",
        "            if preproc is not None:\n",
        "                estimator = Pipeline([('pre', preproc), ('model', actual_model)])\n",
        "            else:\n",
        "                estimator = actual_model\n",
        "            pdp_cfg = settings['pdp_ice']\n",
        "            features_for_pdp = feat_names[:pdp_cfg['top_n_features']]\n",
        "            for feat in features_for_pdp:\n",
        "                fig, ax = plt.subplots()\n",
        "                try:\n",
        "                    # Added check for constant feature\n",
        "                    if X_raw[feat].nunique() < 2:\n",
        "                        logger.warning(f\"Skipping PDP/ICE for {domain}/{target}/{feat}: only {X_raw[feat].nunique()} unique value(s). Feature is constant or has insufficient variation for plotting.\")\n",
        "                        plt.close(fig) # Ensure any implicitly created figure is closed if the plot is skipped\n",
        "                        continue # Skip to the next feature\n",
        "\n",
        "                    PartialDependenceDisplay.from_estimator(\n",
        "                         estimator, X_raw, [feat],\n",
        "                        grid_resolution=pdp_cfg['grid_points'],\n",
        "                        kind='both',\n",
        "                        ice_lines_kw={'alpha': 0.3},\n",
        "                        ax=ax,\n",
        "                        target=1\n",
        "                    )\n",
        "                    plt.tight_layout()\n",
        "                    savep = os.path.join(out_dir, f'plots_pdp_ice_{feat}.png')\n",
        "                    fig.savefig(savep, bbox_inches='tight')\n",
        "                    logger.info(f\"Saved PDP/ICE for {domain}/{target}/{feat}\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Could not plot PDP/ICE for {domain}/{target}/{feat}: {e}\")\n",
        "                finally:\n",
        "                    plt.close(fig) # Ensure figure is closed even if an error occurred\n",
        "\n",
        "            dep_n = settings['dependence']['top_n_features']\n",
        "            features_for_dep_plot = feat_names[:dep_n]\n",
        "            for feat in features_for_dep_plot:\n",
        "                # Removed: fig = plt.figure() - Let SHAP manage figure creation initially\n",
        "                try:\n",
        "                    shap.dependence_plot(feat, shap_vals, X_proc,\n",
        "                                          interaction_index='auto', show=False)\n",
        "                    fig = plt.gcf() # Get the current figure that shap.dependence_plot has drawn on\n",
        "                    savep = os.path.join(out_dir, f'dep_int_{feat}.png')\n",
        "                    fig.savefig(savep, bbox_inches='tight')\n",
        "                    logger.info(f\"Saved dependence plot for {domain}/{target}/{feat}\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Could not plot dependence plot for {domain}/{target}/{feat}: {e}\")\n",
        "                finally:\n",
        "                    plt.close(fig) # Close figure after saving\n",
        "\n",
        "            if expl_type == 'TreeExplainer':\n",
        "                inter_cfg = settings['interaction']\n",
        "                top_feats = get_top_n_features(shap_vals, feat_names, n=inter_cfg['top_n_features'])\n",
        "                subset = X_proc[top_feats]\n",
        "                rows = min(inter_cfg['subsample_size'], len(subset))\n",
        "                subset_samp = subset.sample(rows, random_state=RND)\n",
        "                explainer = shap.TreeExplainer(actual_model, background)\n",
        "                inter_vals = explainer.shap_interaction_values(subset_samp)\n",
        "\n",
        "                # --- FIX 2: HANDLE CLASSIFICATION LIST OUTPUT ---\n",
        "                if isinstance(inter_vals, list):\n",
        "                    # for binary/multiclass, take the “positive‐class” interaction matrix\n",
        "                    inter_vals = inter_vals[1]\n",
        "\n",
        "                mi = np.abs(inter_vals).mean(axis=0)\n",
        "                df = pd.DataFrame(mi, index=top_feats, columns=top_feats)\n",
        "\n",
        "                # --- FIX 1: EMIT A LONG \"feature1,feature2,mean_interaction\" TABLE ---\n",
        "                # keep only upper triangle, stack into long form\n",
        "                pairs = (\n",
        "                    df.where(np.triu(np.ones(df.shape), k=1).astype(bool))\n",
        "                      .stack()\n",
        "                      .reset_index()\n",
        "                      .rename(columns={\n",
        "                          'level_0': 'feature1',\n",
        "                          'level_1': 'feature2',\n",
        "                          0:         'mean_interaction'\n",
        "                      })\n",
        "                )\n",
        "                savef = os.path.join(out_dir, 'interaction_summary.csv')\n",
        "                pairs.to_csv(savef, index=False)\n",
        "                logger.info(f\"Saved interaction summary for {domain}/{target}\")\n",
        "\n",
        "    # ----------------------------------------------------------------------------------\n",
        "    # MODIFIED REGRESSION BLOCK STARTS HERE\n",
        "    # ----------------------------------------------------------------------------------\n",
        "    else: # regression\n",
        "        logger.info(\"Starting modified regression analysis.\")\n",
        "\n",
        "        # MODIFIED: Changed keys to PascalCase to match phase1's output directories\n",
        "        target_to_method_map = {\n",
        "            \"Storytelling\": \"XGBoost\",\n",
        "            \"SpaceUse\": \"XGBoost\",\n",
        "            \"Rhythm\": \"catboost\",\n",
        "            \"PublicInvolvement\": \"XGBoost\",\n",
        "            \"MovementTechnique\": \"XGBoost\",\n",
        "            \"HumanReproducibility\": \"XGBoost\",\n",
        "            \"HumanCharacterization\": \"catboost\"\n",
        "        }\n",
        "\n",
        "        method_folder_map = {\n",
        "            \"catboost\": \"CatBoost\",\n",
        "            \"ridge\": \"Ridge Pipeline\",\n",
        "            \"XGBoost\": \"XGBoost\"\n",
        "        }\n",
        "\n",
        "        for target, method_short_name in target_to_method_map.items():\n",
        "\n",
        "            if method_short_name not in method_folder_map:\n",
        "                logger.warning(f\"Method '{method_short_name}' for target '{target}' is not defined in method_folder_map. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            method_folder_name = method_folder_map[method_short_name]\n",
        "\n",
        "            # --- CHANGE: Define a single directory for both input and output ---\n",
        "            # All files will be READ from and SAVED to this location.\n",
        "            # This 'target' is now PascalCase and directly matches the folders created by phase1\n",
        "            io_dir = os.path.join(base_dir, \"result\", target)\n",
        "            os.makedirs(io_dir, exist_ok=True)\n",
        "\n",
        "            logger.info(f\"Processing target: '{target}' with method: '{method_folder_name}'\")\n",
        "            logger.info(f\"  > Reading from and saving to: {io_dir}\")\n",
        "\n",
        "            # The config file is now expected inside the 'result' directory\n",
        "            cfg_path = os.path.join(io_dir, 'config.json')\n",
        "            if not os.path.exists(cfg_path):\n",
        "                logger.warning(f\"Config file not found: {cfg_path}. Did a previous step save it here? Skipping.\")\n",
        "                continue\n",
        "\n",
        "            cfg = json.load(open(cfg_path))\n",
        "            model_path = cfg['model_path']\n",
        "            bg_path = cfg['background_path']\n",
        "            eval_path = cfg['eval_data_path']\n",
        "            fn_path = cfg['feature_names_path']\n",
        "            raw_path = cfg['raw_shap_path']\n",
        "            expl_type = cfg['explainer_type']\n",
        "            X_raw = pd.read_csv(eval_path)\n",
        "            feat_names = pd.read_csv(fn_path, header=None).iloc[:,0].tolist()\n",
        "            shap_vals = np.load(raw_path)\n",
        "            background = pd.read_csv(bg_path)\n",
        "            model = None\n",
        "            if method_folder_name == 'Ridge Pipeline':\n",
        "                model = joblib.load(model_path)\n",
        "            elif method_folder_name == 'CatBoost':\n",
        "                model = CatBoostRegressor()\n",
        "                model.load_model(model_path)\n",
        "            elif method_folder_name == 'XGBoost':\n",
        "                model = XGBRegressor()\n",
        "                model.load_model(model_path)\n",
        "            else:\n",
        "                logger.warning(f\"Unsupported regression method '{method_folder_name}' for {target}. Skipping.\")\n",
        "                continue\n",
        "            actual_model, preproc = unwrap_pipeline(model)\n",
        "            X_proc = apply_preproc(X_raw, preproc, feat_names)\n",
        "            if preproc is not None:\n",
        "                estimator = Pipeline([('pre', preproc), ('model', actual_model)])\n",
        "            else:\n",
        "                estimator = actual_model\n",
        "            pdp_cfg = settings['pdp_ice']\n",
        "            features_for_pdp = feat_names[:pdp_cfg['top_n_features']]\n",
        "            for feat_orig in features_for_pdp:\n",
        "                fig, ax = plt.subplots()\n",
        "                try:\n",
        "                    # Added check for constant feature\n",
        "                    if X_raw[feat_orig].nunique() < 2:\n",
        "                        logger.warning(f\"Skipping PDP/ICE for {method_folder_name}/{target}/{feat_orig}: only {X_raw[feat_orig].nunique()} unique value(s). Feature is constant or has insufficient variation for plotting.\")\n",
        "                        plt.close(fig) # Ensure any implicitly created figure is closed if the plot is skipped\n",
        "                        continue # Skip to the next feature\n",
        "\n",
        "                    if method_folder_name == 'Ridge Pipeline':\n",
        "                        feat_for_pdp = f'scale_all__{feat_orig}'\n",
        "                    else:\n",
        "                        feat_for_pdp = feat_orig\n",
        "                    PartialDependenceDisplay.from_estimator(\n",
        "                        estimator, X_raw, [feat_for_pdp],\n",
        "                        grid_resolution=pdp_cfg['grid_points'],\n",
        "                        kind='both',\n",
        "                        ice_lines_kw={'alpha':0.3},\n",
        "                        ax=ax\n",
        "                       )\n",
        "                    # Save plot to the unified I/O directory\n",
        "                    savep = os.path.join(io_dir, f'plots_pdp_ice_{feat_orig}.png')\n",
        "                    fig.savefig(savep, bbox_inches='tight')\n",
        "                    logger.info(f\"Saved PDP/ICE for {method_folder_name}/{target}/{feat_orig}\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Could not plot PDP/ICE for {method_folder_name}/{target}/{feat_orig}: {e}\")\n",
        "                finally:\n",
        "                    plt.close(fig) # Close figure after saving\n",
        "\n",
        "            dep_n = settings['dependence']['top_n_features']\n",
        "            features_for_dep_plot = feat_names[:dep_n]\n",
        "            for feat in features_for_dep_plot:\n",
        "                # Removed: fig = plt.figure() - Let SHAP manage figure creation initially\n",
        "                try:\n",
        "                    shap.dependence_plot(feat, shap_vals, X_proc,\n",
        "                                          interaction_index='auto', show=False)\n",
        "                    fig = plt.gcf() # Get the current figure that shap.dependence_plot has drawn on\n",
        "                    savep = os.path.join(io_dir, f'dep_int_{feat}.png')\n",
        "                    fig.savefig(savep, bbox_inches='tight')\n",
        "                    logger.info(f\"Saved dependence plot for {method_folder_name}/{target}/{feat}\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Could not plot dependence plot for {method_folder_name}/{target}/{feat}: {e}\")\n",
        "                finally:\n",
        "                    plt.close(fig) # Close figure after saving\n",
        "\n",
        "            if expl_type == 'TreeExplainer':\n",
        "                inter_cfg = settings['interaction']\n",
        "                top_feats = get_top_n_features(shap_vals, feat_names, n=inter_cfg['top_n_features'])\n",
        "                subset = X_proc[top_feats]\n",
        "                rows = min(inter_cfg['subsample_size'], len(subset))\n",
        "                subset_samp = subset.sample(rows, random_state=RND)\n",
        "                explainer = shap.TreeExplainer(actual_model, background)\n",
        "                inter_vals = explainer.shap_interaction_values(subset_samp)\n",
        "\n",
        "                # Regression does not return a list, so no list handling is needed here.\n",
        "\n",
        "                mi = np.abs(inter_vals).mean(axis=0)\n",
        "                df = pd.DataFrame(mi, index=top_feats, columns=top_feats)\n",
        "\n",
        "                # --- FIX 1: EMIT A LONG \"feature1,feature2,mean_interaction\" TABLE ---\n",
        "                # keep only upper triangle, stack into long form\n",
        "                pairs = (\n",
        "                    df.where(np.triu(np.ones(df.shape), k=1).astype(bool))\n",
        "                      .stack()\n",
        "                      .reset_index()\n",
        "                      .rename(columns={\n",
        "                          'level_0': 'feature1',\n",
        "                          'level_1': 'feature2',\n",
        "                          0:         'mean_interaction'\n",
        "                      })\n",
        "                )\n",
        "                savef = os.path.join(io_dir, 'interaction_summary.csv')\n",
        "                pairs.to_csv(savef, index=False)\n",
        "                logger.info(f\"Saved interaction summary for {method_folder_name}/{target}\")"
      ],
      "metadata": {
        "id": "1TftaU8omR-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e2e576-e35d-4eb8-9aef-1dd2597907ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-06 20:32:11,461 [INFO] Saved PDP/ICE for classification/HumanCharacterization/timeDuration\n",
            "2025-07-06 20:32:13,068 [INFO] Saved PDP/ICE for classification/HumanCharacterization/nMovements\n",
            "2025-07-06 20:32:15,972 [INFO] Saved PDP/ICE for classification/HumanCharacterization/movementsDifficulty\n",
            "2025-07-06 20:32:15,999 [WARNING] Could not plot PDP/ICE for classification/HumanCharacterization/robotSpeech: cannot reshape array of size 1 into shape (2)\n",
            "2025-07-06 20:32:17,587 [INFO] Saved PDP/ICE for classification/HumanCharacterization/acrobaticMovements\n",
            "2025-07-06 20:32:18,073 [INFO] Saved dependence plot for classification/HumanCharacterization/timeDuration\n",
            "2025-07-06 20:32:18,584 [INFO] Saved dependence plot for classification/HumanCharacterization/nMovements\n",
            "2025-07-06 20:32:19,170 [INFO] Saved dependence plot for classification/HumanCharacterization/movementsDifficulty\n",
            "2025-07-06 20:32:19,532 [INFO] Saved dependence plot for classification/HumanCharacterization/robotSpeech\n",
            "2025-07-06 20:32:20,017 [INFO] Saved dependence plot for classification/HumanCharacterization/acrobaticMovements\n",
            "2025-07-06 20:32:20,085 [INFO] Saved interaction summary for classification/HumanCharacterization\n",
            "2025-07-06 20:32:23,011 [INFO] Saved PDP/ICE for classification/MovementTechnique/timeDuration\n",
            "2025-07-06 20:32:24,336 [INFO] Saved PDP/ICE for classification/MovementTechnique/nMovements\n",
            "2025-07-06 20:32:27,216 [INFO] Saved PDP/ICE for classification/MovementTechnique/movementsDifficulty\n",
            "2025-07-06 20:32:27,242 [WARNING] Could not plot PDP/ICE for classification/MovementTechnique/robotSpeech: cannot reshape array of size 1 into shape (2)\n",
            "2025-07-06 20:32:29,682 [INFO] Saved PDP/ICE for classification/MovementTechnique/acrobaticMovements\n",
            "2025-07-06 20:32:29,956 [INFO] Saved dependence plot for classification/MovementTechnique/timeDuration\n",
            "2025-07-06 20:32:30,235 [INFO] Saved dependence plot for classification/MovementTechnique/nMovements\n",
            "2025-07-06 20:32:30,438 [INFO] Saved dependence plot for classification/MovementTechnique/movementsDifficulty\n",
            "2025-07-06 20:32:30,654 [INFO] Saved dependence plot for classification/MovementTechnique/robotSpeech\n",
            "2025-07-06 20:32:30,873 [INFO] Saved dependence plot for classification/MovementTechnique/acrobaticMovements\n",
            "2025-07-06 20:32:30,898 [INFO] Saved interaction summary for classification/MovementTechnique\n",
            "2025-07-06 20:32:33,784 [INFO] Saved PDP/ICE for classification/PublicInvolvement/timeDuration\n",
            "2025-07-06 20:32:35,176 [INFO] Saved PDP/ICE for classification/PublicInvolvement/nMovements\n",
            "2025-07-06 20:32:38,203 [INFO] Saved PDP/ICE for classification/PublicInvolvement/movementsDifficulty\n",
            "2025-07-06 20:32:38,230 [WARNING] Could not plot PDP/ICE for classification/PublicInvolvement/robotSpeech: cannot reshape array of size 1 into shape (2)\n",
            "2025-07-06 20:32:40,827 [INFO] Saved PDP/ICE for classification/PublicInvolvement/acrobaticMovements\n",
            "2025-07-06 20:32:41,123 [INFO] Saved dependence plot for classification/PublicInvolvement/timeDuration\n",
            "2025-07-06 20:32:41,432 [INFO] Saved dependence plot for classification/PublicInvolvement/nMovements\n",
            "2025-07-06 20:32:41,738 [INFO] Saved dependence plot for classification/PublicInvolvement/movementsDifficulty\n",
            "2025-07-06 20:32:42,020 [INFO] Saved dependence plot for classification/PublicInvolvement/robotSpeech\n",
            "2025-07-06 20:32:42,324 [INFO] Saved dependence plot for classification/PublicInvolvement/acrobaticMovements\n",
            "2025-07-06 20:32:42,367 [INFO] Saved interaction summary for classification/PublicInvolvement\n",
            "2025-07-06 20:32:45,094 [INFO] Saved PDP/ICE for classification/SpaceUse/timeDuration\n",
            "2025-07-06 20:32:46,972 [INFO] Saved PDP/ICE for classification/SpaceUse/nMovements\n",
            "2025-07-06 20:32:49,971 [INFO] Saved PDP/ICE for classification/SpaceUse/movementsDifficulty\n",
            "2025-07-06 20:32:49,997 [WARNING] Could not plot PDP/ICE for classification/SpaceUse/robotSpeech: cannot reshape array of size 1 into shape (2)\n",
            "2025-07-06 20:32:52,315 [INFO] Saved PDP/ICE for classification/SpaceUse/acrobaticMovements\n",
            "2025-07-06 20:32:52,588 [INFO] Saved dependence plot for classification/SpaceUse/timeDuration\n",
            "2025-07-06 20:32:52,912 [INFO] Saved dependence plot for classification/SpaceUse/nMovements\n",
            "2025-07-06 20:32:53,207 [INFO] Saved dependence plot for classification/SpaceUse/movementsDifficulty\n",
            "2025-07-06 20:32:53,476 [INFO] Saved dependence plot for classification/SpaceUse/robotSpeech\n",
            "2025-07-06 20:32:53,773 [INFO] Saved dependence plot for classification/SpaceUse/acrobaticMovements\n",
            "2025-07-06 20:32:53,821 [INFO] Saved interaction summary for classification/SpaceUse\n",
            "2025-07-06 20:32:57,482 [INFO] Saved PDP/ICE for classification/Rhythm/timeDuration\n",
            "2025-07-06 20:32:59,710 [INFO] Saved PDP/ICE for classification/Rhythm/nMovements\n",
            "2025-07-06 20:33:02,690 [INFO] Saved PDP/ICE for classification/Rhythm/movementsDifficulty\n",
            "2025-07-06 20:33:02,722 [WARNING] Could not plot PDP/ICE for classification/Rhythm/robotSpeech: cannot reshape array of size 1 into shape (2)\n",
            "2025-07-06 20:33:05,280 [INFO] Saved PDP/ICE for classification/Rhythm/acrobaticMovements\n",
            "2025-07-06 20:33:05,564 [INFO] Saved dependence plot for classification/Rhythm/timeDuration\n",
            "2025-07-06 20:33:05,869 [INFO] Saved dependence plot for classification/Rhythm/nMovements\n",
            "2025-07-06 20:33:06,182 [INFO] Saved dependence plot for classification/Rhythm/movementsDifficulty\n",
            "2025-07-06 20:33:06,472 [INFO] Saved dependence plot for classification/Rhythm/robotSpeech\n",
            "2025-07-06 20:33:06,769 [INFO] Saved dependence plot for classification/Rhythm/acrobaticMovements\n",
            "2025-07-06 20:33:06,801 [INFO] Saved interaction summary for classification/Rhythm\n",
            "2025-07-06 20:33:08,787 [INFO] Saved PDP/ICE for classification/HumanReproducibility/timeDuration\n",
            "2025-07-06 20:33:10,496 [INFO] Saved PDP/ICE for classification/HumanReproducibility/nMovements\n",
            "2025-07-06 20:33:12,595 [INFO] Saved PDP/ICE for classification/HumanReproducibility/movementsDifficulty\n",
            "2025-07-06 20:33:12,622 [WARNING] Could not plot PDP/ICE for classification/HumanReproducibility/robotSpeech: cannot reshape array of size 1 into shape (2)\n",
            "2025-07-06 20:33:14,700 [INFO] Saved PDP/ICE for classification/HumanReproducibility/acrobaticMovements\n",
            "2025-07-06 20:33:14,967 [INFO] Saved dependence plot for classification/HumanReproducibility/timeDuration\n",
            "2025-07-06 20:33:15,274 [INFO] Saved dependence plot for classification/HumanReproducibility/nMovements\n",
            "2025-07-06 20:33:15,553 [INFO] Saved dependence plot for classification/HumanReproducibility/movementsDifficulty\n",
            "2025-07-06 20:33:15,849 [INFO] Saved dependence plot for classification/HumanReproducibility/robotSpeech\n",
            "2025-07-06 20:33:16,141 [INFO] Saved dependence plot for classification/HumanReproducibility/acrobaticMovements\n",
            "2025-07-06 20:33:16,167 [INFO] Saved interaction summary for classification/HumanReproducibility\n",
            "2025-07-06 20:33:18,062 [INFO] Saved PDP/ICE for classification/StoryTelling/timeDuration\n",
            "2025-07-06 20:33:20,642 [INFO] Saved PDP/ICE for classification/StoryTelling/nMovements\n",
            "/tmp/ipython-input-8-3748979914.py:117: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
            "  fig.savefig(savep, bbox_inches='tight')\n",
            "2025-07-06 20:33:27,990 [INFO] Saved PDP/ICE for classification/StoryTelling/movementsDifficulty\n",
            "2025-07-06 20:33:28,074 [WARNING] Could not plot PDP/ICE for classification/StoryTelling/robotSpeech: cannot reshape array of size 1 into shape (2)\n",
            "2025-07-06 20:33:33,643 [INFO] Saved PDP/ICE for classification/StoryTelling/acrobaticMovements\n",
            "2025-07-06 20:33:33,919 [INFO] Saved dependence plot for classification/StoryTelling/timeDuration\n",
            "2025-07-06 20:33:34,214 [INFO] Saved dependence plot for classification/StoryTelling/nMovements\n",
            "2025-07-06 20:33:34,508 [INFO] Saved dependence plot for classification/StoryTelling/movementsDifficulty\n",
            "2025-07-06 20:33:34,815 [INFO] Saved dependence plot for classification/StoryTelling/robotSpeech\n",
            "2025-07-06 20:33:35,110 [INFO] Saved dependence plot for classification/StoryTelling/acrobaticMovements\n",
            "2025-07-06 20:33:35,152 [INFO] Saved interaction summary for classification/StoryTelling\n",
            "2025-07-06 20:33:35,153 [INFO] Starting modified regression analysis.\n",
            "2025-07-06 20:33:35,158 [INFO] Processing target: 'Storytelling' with method: 'XGBoost'\n",
            "2025-07-06 20:33:35,159 [INFO]   > Reading from and saving to: /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/Storytelling\n",
            "2025-07-06 20:33:37,857 [INFO] Saved PDP/ICE for XGBoost/Storytelling/timeDuration\n",
            "2025-07-06 20:33:39,871 [INFO] Saved PDP/ICE for XGBoost/Storytelling/nMovements\n",
            "2025-07-06 20:33:41,843 [INFO] Saved PDP/ICE for XGBoost/Storytelling/movementsDifficulty\n",
            "2025-07-06 20:33:44,267 [INFO] Saved PDP/ICE for XGBoost/Storytelling/robotSpeech\n",
            "2025-07-06 20:33:46,249 [INFO] Saved PDP/ICE for XGBoost/Storytelling/acrobaticMovements\n",
            "2025-07-06 20:33:46,461 [INFO] Saved dependence plot for XGBoost/Storytelling/timeDuration\n",
            "2025-07-06 20:33:46,700 [INFO] Saved dependence plot for XGBoost/Storytelling/nMovements\n",
            "2025-07-06 20:33:46,954 [INFO] Saved dependence plot for XGBoost/Storytelling/movementsDifficulty\n",
            "2025-07-06 20:33:47,179 [INFO] Saved dependence plot for XGBoost/Storytelling/robotSpeech\n",
            "2025-07-06 20:33:47,407 [INFO] Saved dependence plot for XGBoost/Storytelling/acrobaticMovements\n",
            "2025-07-06 20:33:47,487 [INFO] Saved interaction summary for XGBoost/Storytelling\n",
            "2025-07-06 20:33:47,488 [INFO] Processing target: 'SpaceUse' with method: 'XGBoost'\n",
            "2025-07-06 20:33:47,491 [INFO]   > Reading from and saving to: /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/SpaceUse\n",
            "2025-07-06 20:33:50,071 [INFO] Saved PDP/ICE for XGBoost/SpaceUse/timeDuration\n",
            "2025-07-06 20:33:51,656 [INFO] Saved PDP/ICE for XGBoost/SpaceUse/nMovements\n",
            "2025-07-06 20:33:54,057 [INFO] Saved PDP/ICE for XGBoost/SpaceUse/movementsDifficulty\n",
            "2025-07-06 20:33:55,943 [INFO] Saved PDP/ICE for XGBoost/SpaceUse/robotSpeech\n",
            "2025-07-06 20:33:57,845 [INFO] Saved PDP/ICE for XGBoost/SpaceUse/acrobaticMovements\n",
            "2025-07-06 20:33:58,065 [INFO] Saved dependence plot for XGBoost/SpaceUse/timeDuration\n",
            "2025-07-06 20:33:58,315 [INFO] Saved dependence plot for XGBoost/SpaceUse/nMovements\n",
            "2025-07-06 20:33:58,536 [INFO] Saved dependence plot for XGBoost/SpaceUse/movementsDifficulty\n",
            "2025-07-06 20:33:59,243 [INFO] Saved dependence plot for XGBoost/SpaceUse/robotSpeech\n",
            "2025-07-06 20:33:59,474 [INFO] Saved dependence plot for XGBoost/SpaceUse/acrobaticMovements\n",
            "2025-07-06 20:33:59,502 [INFO] Saved interaction summary for XGBoost/SpaceUse\n",
            "2025-07-06 20:33:59,503 [INFO] Processing target: 'Rhythm' with method: 'CatBoost'\n",
            "2025-07-06 20:33:59,504 [INFO]   > Reading from and saving to: /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/Rhythm\n",
            "2025-07-06 20:34:00,703 [INFO] Saved PDP/ICE for CatBoost/Rhythm/timeDuration\n",
            "2025-07-06 20:34:02,050 [INFO] Saved PDP/ICE for CatBoost/Rhythm/nMovements\n",
            "2025-07-06 20:34:05,053 [INFO] Saved PDP/ICE for CatBoost/Rhythm/movementsDifficulty\n",
            "2025-07-06 20:34:06,942 [INFO] Saved PDP/ICE for CatBoost/Rhythm/robotSpeech\n",
            "2025-07-06 20:34:08,864 [INFO] Saved PDP/ICE for CatBoost/Rhythm/acrobaticMovements\n",
            "2025-07-06 20:34:09,078 [INFO] Saved dependence plot for CatBoost/Rhythm/timeDuration\n",
            "2025-07-06 20:34:09,761 [INFO] Saved dependence plot for CatBoost/Rhythm/nMovements\n",
            "2025-07-06 20:34:09,980 [INFO] Saved dependence plot for CatBoost/Rhythm/movementsDifficulty\n",
            "2025-07-06 20:34:10,210 [INFO] Saved dependence plot for CatBoost/Rhythm/robotSpeech\n",
            "2025-07-06 20:34:10,447 [INFO] Saved dependence plot for CatBoost/Rhythm/acrobaticMovements\n",
            "2025-07-06 20:34:10,486 [INFO] Saved interaction summary for CatBoost/Rhythm\n",
            "2025-07-06 20:34:10,487 [INFO] Processing target: 'PublicInvolvement' with method: 'XGBoost'\n",
            "2025-07-06 20:34:10,488 [INFO]   > Reading from and saving to: /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/PublicInvolvement\n",
            "2025-07-06 20:34:12,469 [INFO] Saved PDP/ICE for XGBoost/PublicInvolvement/timeDuration\n",
            "2025-07-06 20:34:13,701 [INFO] Saved PDP/ICE for XGBoost/PublicInvolvement/nMovements\n",
            "2025-07-06 20:34:17,053 [INFO] Saved PDP/ICE for XGBoost/PublicInvolvement/movementsDifficulty\n",
            "2025-07-06 20:34:18,928 [INFO] Saved PDP/ICE for XGBoost/PublicInvolvement/robotSpeech\n",
            "2025-07-06 20:34:23,179 [INFO] Saved PDP/ICE for XGBoost/PublicInvolvement/acrobaticMovements\n",
            "2025-07-06 20:34:23,987 [INFO] Saved dependence plot for XGBoost/PublicInvolvement/timeDuration\n",
            "2025-07-06 20:34:24,369 [INFO] Saved dependence plot for XGBoost/PublicInvolvement/nMovements\n",
            "2025-07-06 20:34:24,926 [INFO] Saved dependence plot for XGBoost/PublicInvolvement/movementsDifficulty\n",
            "2025-07-06 20:34:25,484 [INFO] Saved dependence plot for XGBoost/PublicInvolvement/robotSpeech\n",
            "2025-07-06 20:34:25,728 [INFO] Saved dependence plot for XGBoost/PublicInvolvement/acrobaticMovements\n",
            "2025-07-06 20:34:25,937 [INFO] Saved interaction summary for XGBoost/PublicInvolvement\n",
            "2025-07-06 20:34:25,946 [INFO] Processing target: 'MovementTechnique' with method: 'XGBoost'\n",
            "2025-07-06 20:34:25,947 [INFO]   > Reading from and saving to: /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/MovementTechnique\n",
            "2025-07-06 20:34:31,617 [INFO] Saved PDP/ICE for XGBoost/MovementTechnique/timeDuration\n",
            "2025-07-06 20:34:34,879 [INFO] Saved PDP/ICE for XGBoost/MovementTechnique/nMovements\n",
            "2025-07-06 20:34:38,384 [INFO] Saved PDP/ICE for XGBoost/MovementTechnique/movementsDifficulty\n",
            "2025-07-06 20:34:42,365 [INFO] Saved PDP/ICE for XGBoost/MovementTechnique/robotSpeech\n",
            "2025-07-06 20:34:45,187 [INFO] Saved PDP/ICE for XGBoost/MovementTechnique/acrobaticMovements\n",
            "2025-07-06 20:34:45,392 [INFO] Saved dependence plot for XGBoost/MovementTechnique/timeDuration\n",
            "2025-07-06 20:34:45,634 [INFO] Saved dependence plot for XGBoost/MovementTechnique/nMovements\n",
            "2025-07-06 20:34:45,879 [INFO] Saved dependence plot for XGBoost/MovementTechnique/movementsDifficulty\n",
            "2025-07-06 20:34:46,091 [INFO] Saved dependence plot for XGBoost/MovementTechnique/robotSpeech\n",
            "2025-07-06 20:34:46,347 [INFO] Saved dependence plot for XGBoost/MovementTechnique/acrobaticMovements\n",
            "2025-07-06 20:34:46,431 [INFO] Saved interaction summary for XGBoost/MovementTechnique\n",
            "2025-07-06 20:34:46,432 [INFO] Processing target: 'HumanReproducibility' with method: 'XGBoost'\n",
            "2025-07-06 20:34:46,434 [INFO]   > Reading from and saving to: /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/HumanReproducibility\n",
            "2025-07-06 20:34:48,086 [INFO] Saved PDP/ICE for XGBoost/HumanReproducibility/timeDuration\n",
            "2025-07-06 20:34:49,728 [INFO] Saved PDP/ICE for XGBoost/HumanReproducibility/nMovements\n",
            "2025-07-06 20:34:50,817 [INFO] Saved PDP/ICE for XGBoost/HumanReproducibility/movementsDifficulty\n",
            "2025-07-06 20:34:53,209 [INFO] Saved PDP/ICE for XGBoost/HumanReproducibility/robotSpeech\n",
            "2025-07-06 20:34:56,123 [INFO] Saved PDP/ICE for XGBoost/HumanReproducibility/acrobaticMovements\n",
            "2025-07-06 20:34:56,351 [INFO] Saved dependence plot for XGBoost/HumanReproducibility/timeDuration\n",
            "2025-07-06 20:34:56,592 [INFO] Saved dependence plot for XGBoost/HumanReproducibility/nMovements\n",
            "2025-07-06 20:34:56,844 [INFO] Saved dependence plot for XGBoost/HumanReproducibility/movementsDifficulty\n",
            "2025-07-06 20:34:57,071 [INFO] Saved dependence plot for XGBoost/HumanReproducibility/robotSpeech\n",
            "2025-07-06 20:34:57,325 [INFO] Saved dependence plot for XGBoost/HumanReproducibility/acrobaticMovements\n",
            "2025-07-06 20:34:57,365 [INFO] Saved interaction summary for XGBoost/HumanReproducibility\n",
            "2025-07-06 20:34:57,366 [INFO] Processing target: 'HumanCharacterization' with method: 'CatBoost'\n",
            "2025-07-06 20:34:57,367 [INFO]   > Reading from and saving to: /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/HumanCharacterization\n",
            "2025-07-06 20:34:59,137 [INFO] Saved PDP/ICE for CatBoost/HumanCharacterization/timeDuration\n",
            "2025-07-06 20:35:00,300 [INFO] Saved PDP/ICE for CatBoost/HumanCharacterization/nMovements\n",
            "2025-07-06 20:35:01,395 [INFO] Saved PDP/ICE for CatBoost/HumanCharacterization/movementsDifficulty\n",
            "2025-07-06 20:35:03,736 [INFO] Saved PDP/ICE for CatBoost/HumanCharacterization/robotSpeech\n",
            "2025-07-06 20:35:05,693 [INFO] Saved PDP/ICE for CatBoost/HumanCharacterization/acrobaticMovements\n",
            "2025-07-06 20:35:05,908 [INFO] Saved dependence plot for CatBoost/HumanCharacterization/timeDuration\n",
            "2025-07-06 20:35:06,295 [INFO] Saved dependence plot for CatBoost/HumanCharacterization/nMovements\n",
            "2025-07-06 20:35:06,632 [INFO] Saved dependence plot for CatBoost/HumanCharacterization/movementsDifficulty\n",
            "2025-07-06 20:35:06,959 [INFO] Saved dependence plot for CatBoost/HumanCharacterization/robotSpeech\n",
            "2025-07-06 20:35:07,304 [INFO] Saved dependence plot for CatBoost/HumanCharacterization/acrobaticMovements\n",
            "2025-07-06 20:35:07,369 [INFO] Saved interaction summary for CatBoost/HumanCharacterization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "hope last try on phase3 phase-3"
      ],
      "metadata": {
        "id": "X0x-wO0eKQqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import yaml\n",
        "import logging\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import resample # For bootstrap sampling\n",
        "from scipy.stats import spearmanr # For Spearman's rank correlation (though not used for per-feature stability directly now)\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor\n",
        "# import matplotlib.pyplot as plt # Commented out as no plots are generated in Phase 3 as per current spec\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    force=True\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Load settings\n",
        "try:\n",
        "    with open('settings.yaml') as f:\n",
        "        settings = yaml.safe_load(f)\n",
        "except FileNotFoundError:\n",
        "    logger.error(\"settings.yaml not found. Please ensure it's in the current directory.\")\n",
        "    exit(1) # Exit with an error code\n",
        "\n",
        "RND = settings.get('random_seed', 42)\n",
        "PROJECT_ROOT = \"/content/Evaluations_on_Robotic_Choreographies/\"\n",
        "SHAP_ROOT = os.path.join(PROJECT_ROOT, 'shap')\n",
        "\n",
        "# Validate essential settings for Phase 3\n",
        "if 'stability' not in settings:\n",
        "    logger.error(\"Missing 'stability' section in settings.yaml. Please add it with 'bootstrap_samples' and 'random_seed_offset'.\")\n",
        "    exit(1)\n",
        "if 'bootstrap_samples' not in settings['stability']:\n",
        "    logger.error(\"Missing 'stability.bootstrap_samples' in settings.yaml. Please add it.\")\n",
        "    exit(1)\n",
        "if 'random_seed_offset' not in settings['stability']:\n",
        "    logger.error(\"Missing 'stability.random_seed_offset' in settings.yaml. Please add it.\")\n",
        "    exit(1)\n",
        "if 'subgroup_analysis' not in settings:\n",
        "    logger.warning(\"Missing 'subgroup_analysis' section in settings.yaml. Subgroup analysis will be skipped.\")\n",
        "    settings['subgroup_analysis'] = {'min_group_size': 0, 'categorical_features': []}\n",
        "\n",
        "# Helper: unwrap pipeline\n",
        "def unwrap_pipeline(model):\n",
        "    preproc = None\n",
        "    actual = model\n",
        "    if isinstance(model, Pipeline):\n",
        "        actual = model.steps[-1][1]\n",
        "        if len(model.steps) > 1:\n",
        "            preproc = Pipeline(model.steps[:-1])\n",
        "    return actual, preproc\n",
        "\n",
        "# Helper: apply preprocessing\n",
        "def apply_preproc(df, preproc, feat_names):\n",
        "    \"\"\"Applies preprocessing if a preproc pipeline is provided.\"\"\"\n",
        "    if preproc is not None:\n",
        "        arr = preproc.transform(df)\n",
        "        return pd.DataFrame(arr, columns=feat_names, index=df.index)\n",
        "    if feat_names is not None:\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            df = pd.DataFrame(df, columns=feat_names, index=df.index if hasattr(df, 'index') else None)\n",
        "        return df.copy()\n",
        "    return df.copy()\n",
        "\n",
        "# Helper: top-N features by mean abs shap\n",
        "def get_top_n_features(shap_vals, feat_names, n=None):\n",
        "    \"\"\"\n",
        "    Returns feature names ranked by mean absolute SHAP values. If n is None, returns all features ranked.\n",
        "    \"\"\"\n",
        "    if shap_vals.ndim > 1:\n",
        "        means = np.abs(shap_vals).mean(axis=0)\n",
        "    else:\n",
        "        means = np.abs(shap_vals)\n",
        "\n",
        "    if n is None or n >= len(feat_names):\n",
        "        idx = np.argsort(means)[::-1]\n",
        "    else:\n",
        "        actual_n = min(n, len(feat_names))\n",
        "        idx = np.argsort(means)[-actual_n:][::-1]\n",
        "\n",
        "    return [feat_names[i] for i in idx]\n",
        "\n",
        "# New helper function to load models based on file type\n",
        "def load_model(model_path):\n",
        "    \"\"\"Loads a model from the given path.\"\"\"\n",
        "    if model_path.endswith('.pkl') or model_path.endswith('.joblib'):\n",
        "        return joblib.load(model_path)\n",
        "    elif model_path.endswith('.cbm'):\n",
        "        try:\n",
        "            return CatBoostRegressor().load_model(model_path)\n",
        "        except:\n",
        "            return CatBoostClassifier().load_model(model_path)\n",
        "    elif model_path.endswith(('.json', '.json.bst')):\n",
        "        import xgboost as xgb\n",
        "        bst = xgb.Booster()\n",
        "        bst.load_model(model_path)\n",
        "        return bst\n",
        "    elif model_path.endswith(('.keras', '.h5')):\n",
        "        from tensorflow import keras\n",
        "        return keras.models.load_model(model_path)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model file extension: {model_path}\")\n",
        "\n",
        "# Main Phase3 loop\n",
        "logger.info(\"Starting Phase 3: Stability & Subgroup Analysis\")\n",
        "\n",
        "for domain in ['classification', 'regression']:\n",
        "    base_dir = os.path.join(SHAP_ROOT, domain)\n",
        "    if not os.path.exists(base_dir):\n",
        "        logger.warning(f\"Base directory not found for {domain}: {base_dir}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    if domain == 'classification':\n",
        "        target_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
        "    else: # regression\n",
        "        regression_result_dir = os.path.join(base_dir, 'result')\n",
        "        if not os.path.exists(regression_result_dir):\n",
        "            logger.warning(f\"Regression result directory not found: {regression_result_dir}. Skipping.\")\n",
        "            continue\n",
        "        target_dirs = [d for d in os.listdir(regression_result_dir) if os.path.isdir(os.path.join(regression_result_dir, d))]\n",
        "\n",
        "    if not target_dirs:\n",
        "        logger.info(f\"No targets found in {base_dir} for {domain}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    for target in target_dirs:\n",
        "        if domain == 'classification':\n",
        "            io_dir = os.path.join(base_dir, target)\n",
        "        else: # regression\n",
        "            io_dir = os.path.join(regression_result_dir, target)\n",
        "\n",
        "        logger.info(f\"Processing {domain}/{target}\")\n",
        "\n",
        "        cfg_path = os.path.join(io_dir, 'config.json')\n",
        "        if not os.path.exists(cfg_path):\n",
        "            logger.warning(f\"Config file not found: {cfg_path}. Skipping {domain}/{target}.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            cfg = json.load(open(cfg_path))\n",
        "            model_path = cfg['model_path']\n",
        "            bg_path = cfg['background_path']\n",
        "            eval_data_path = cfg['eval_data_path']\n",
        "            fn_path = cfg['feature_names_path']\n",
        "            shap_path = cfg['raw_shap_path']\n",
        "            expl_type = cfg['explainer_type']\n",
        "\n",
        "            X_raw = pd.read_csv(eval_data_path)\n",
        "            feat_names = pd.read_csv(fn_path, header=None).iloc[:,0].tolist()\n",
        "            shap_vals = np.load(shap_path)\n",
        "\n",
        "            if shap_vals.shape[1] != len(feat_names):\n",
        "                logger.error(f\"Mismatch: SHAP values (columns: {shap_vals.shape[1]}) do not match number of feature names ({len(feat_names)}) for {domain}/{target}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            background = pd.read_csv(bg_path)\n",
        "\n",
        "            model = load_model(model_path)\n",
        "            logger.info(f\"Loaded model from {model_path}\")\n",
        "\n",
        "            actual_model, preproc = unwrap_pipeline(model)\n",
        "            X_proc = apply_preproc(X_raw, preproc, feat_names)\n",
        "\n",
        "            explainer = None\n",
        "            if expl_type == 'TreeExplainer':\n",
        "                explainer = shap.TreeExplainer(actual_model, background)\n",
        "            elif expl_type == 'KernelExplainer':\n",
        "                if domain == 'classification':\n",
        "                    explainer = shap.KernelExplainer(actual_model.predict_proba, background)\n",
        "                else: # regression\n",
        "                    explainer = shap.KernelExplainer(actual_model.predict, background)\n",
        "            elif expl_type == 'LinearExplainer':\n",
        "                explainer = shap.LinearExplainer(actual_model, background)\n",
        "\n",
        "            if explainer is None:\n",
        "                logger.error(f\"Unsupported explainer type '{expl_type}' for {domain}/{target}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # --- Bootstrap Stability Analysis ---\n",
        "            stability_cfg = settings['stability']\n",
        "            n_bootstrap_samples = stability_cfg['bootstrap_samples']\n",
        "            random_seed_offset = stability_cfg['random_seed_offset']\n",
        "            stability_top_n_features = stability_cfg.get('top_n_features', len(feat_names)) # Default to all features\n",
        "\n",
        "            logger.info(f\"Starting bootstrap stability analysis for {domain}/{target} with {n_bootstrap_samples} samples.\")\n",
        "\n",
        "            bootstrap_feature_ranks = []\n",
        "            bootstrap_mean_abs_shaps = []\n",
        "\n",
        "            for i in range(n_bootstrap_samples):\n",
        "                current_seed = RND + random_seed_offset + i\n",
        "\n",
        "                if X_proc.empty:\n",
        "                    logger.warning(f\"X_proc is empty for {domain}/{target}. Skipping bootstrap sample {i}.\")\n",
        "                    continue\n",
        "\n",
        "                n_samples_to_take = len(X_proc)\n",
        "\n",
        "                bootstrap_indices = resample(\n",
        "                    np.arange(len(X_proc)),\n",
        "                    replace=True,\n",
        "                    n_samples=n_samples_to_take,\n",
        "                    random_state=current_seed\n",
        "                )\n",
        "\n",
        "                X_bootstrap = X_proc.iloc[bootstrap_indices]\n",
        "                # shap_bootstrap = shap_vals[bootstrap_indices] # No longer directly using pre-computed shap_vals\n",
        "\n",
        "                bootstrap_shap_values = explainer.shap_values(X_bootstrap)\n",
        "\n",
        "                if isinstance(bootstrap_shap_values, list):\n",
        "                    bootstrap_shap_values_combined = np.sum([np.abs(s) for s in bootstrap_shap_values], axis=0)\n",
        "                else:\n",
        "                    bootstrap_shap_values_combined = np.abs(bootstrap_shap_values)\n",
        "\n",
        "                current_mean_abs_shaps = np.mean(bootstrap_shap_values_combined, axis=0)\n",
        "                bootstrap_mean_abs_shaps.append(current_mean_abs_shaps)\n",
        "\n",
        "                current_ranks = pd.Series(current_mean_abs_shaps, index=feat_names).rank(ascending=False)\n",
        "                bootstrap_feature_ranks.append(current_ranks)\n",
        "\n",
        "            if not bootstrap_feature_ranks:\n",
        "                logger.warning(f\"No bootstrap samples were processed for {domain}/{target}. Skipping stability analysis.\")\n",
        "                continue\n",
        "\n",
        "            # Convert list of ranks to DataFrame for stability calculation\n",
        "            # Each column is a feature, each row is a bootstrap sample's rank for that feature\n",
        "            rank_df = pd.DataFrame(bootstrap_feature_ranks, columns=feat_names)\n",
        "\n",
        "            # --- CORRECTED PER-FEATURE STABILITY CALCULATION ---\n",
        "            # Calculate the standard deviation of ranks for each feature across bootstrap samples\n",
        "            rank_stds = rank_df.std(axis=0)\n",
        "\n",
        "            # Normalize the standard deviation to get a stability score (0 to 1, 1 being most stable)\n",
        "            # Max possible std for ranks 1 to N is roughly N / sqrt(12) for uniform distribution\n",
        "            # A simpler normalization: 1 - (std / max_possible_std_deviation)\n",
        "            # Max possible std deviation for ranks 1 to N is when half are rank 1 and half are rank N.\n",
        "            # For N features, ranks range from 1 to N.\n",
        "            # The maximum possible standard deviation of ranks for a feature is roughly (N_features - 1) / 2\n",
        "            # when ranks are perfectly split between 1 and N_features.\n",
        "            num_features = len(feat_names)\n",
        "            if num_features > 1:\n",
        "                max_possible_rank_std = np.std(np.arange(1, num_features + 1)) # Std of perfectly ordered ranks\n",
        "            else:\n",
        "                max_possible_rank_std = 1.0 # If only one feature, it's perfectly stable\n",
        "\n",
        "            # Avoid division by zero if max_possible_rank_std is 0 (e.g., if num_features is 0 or 1)\n",
        "            mean_bootstrap_rho = 1 - (rank_stds / max_possible_rank_std) if max_possible_rank_std > 0 else pd.Series(1.0, index=feat_names)\n",
        "\n",
        "            # Ensure stability scores are not negative (can happen if std > max_possible_std due to approximations/sampling)\n",
        "            mean_bootstrap_rho = mean_bootstrap_rho.clip(lower=0, upper=1)\n",
        "\n",
        "            # Save mean bootstrap rho per feature (now representing actual stability)\n",
        "            mean_rho_save_path = os.path.join(io_dir, f'mean_bootstrap_rho_{domain}_{target}.csv')\n",
        "            mean_bootstrap_rho.to_csv(mean_rho_save_path, header=['stability_rho'])\n",
        "            logger.info(f\"Saved mean bootstrap rho (stability) per feature to {mean_rho_save_path}\")\n",
        "\n",
        "            # Optionally, save the full feature-feature correlation matrix (if still desired for co-ranking analysis)\n",
        "            # This is the original calculation pointed out, which is valid for co-ranking, just not for per-feature stability\n",
        "            feature_rho_matrix = rank_df.corr(method='spearman')\n",
        "            stability_matrix_save_path = os.path.join(io_dir, f'bootstrap_stability_features_{domain}_{target}.csv')\n",
        "            feature_rho_matrix.to_csv(stability_matrix_save_path)\n",
        "            logger.info(f\"Saved feature-feature bootstrap correlation matrix to {stability_matrix_save_path}\")\n",
        "\n",
        "\n",
        "            # --- Subgroup Analysis (remains unchanged) ---\n",
        "            subgroup_cfg = settings['subgroup_analysis']\n",
        "            min_group_size = subgroup_cfg['min_group_size']\n",
        "            categorical_features = subgroup_cfg['categorical_features']\n",
        "\n",
        "            if not categorical_features:\n",
        "                logger.info(f\"No categorical features defined for subgroup analysis in settings.yaml for {domain}/{target}. Skipping subgroup analysis.\")\n",
        "            else:\n",
        "                logger.info(f\"Starting subgroup analysis for {domain}/{target}.\")\n",
        "                subgroup_shap_means = {}\n",
        "\n",
        "                for cat_feat in categorical_features:\n",
        "                    if cat_feat not in X_raw.columns:\n",
        "                        logger.warning(f\"Categorical feature '{cat_feat}' not found in X_raw for {domain}/{target}. Skipping.\")\n",
        "                        continue\n",
        "\n",
        "                    categories = X_raw[cat_feat].unique()\n",
        "                    for category in categories:\n",
        "                        subgroup_indices = X_raw[X_raw[cat_feat] == category].index\n",
        "\n",
        "                        if len(subgroup_indices) < min_group_size:\n",
        "                            logger.info(f\"Subgroup '{category}' for feature '{cat_feat}' has {len(subgroup_indices)} samples, which is less than min_group_size ({min_group_size}). Skipping.\")\n",
        "                            continue\n",
        "\n",
        "                        logger.info(f\"Analyzing subgroups for feature: {cat_feat} - Category: {category} with {len(subgroup_indices)} samples.\")\n",
        "\n",
        "                        shap_subgroup = shap_vals[subgroup_indices]\n",
        "\n",
        "                        if shap_subgroup.ndim == 3:\n",
        "                            mean_abs_shap = np.mean(np.abs(shap_subgroup), axis=(0, 1))\n",
        "                        elif shap_subgroup.ndim == 2:\n",
        "                            mean_abs_shap = np.mean(np.abs(shap_subgroup), axis=0)\n",
        "                        else:\n",
        "                            mean_abs_shap = np.abs(shap_subgroup)\n",
        "                            if mean_abs_shap.ndim > 1:\n",
        "                                mean_abs_shap = mean_abs_shap.flatten()\n",
        "\n",
        "                        col_name = f\"subgroup_{cat_feat}_{category}_mean_abs_shap\"\n",
        "                        subgroup_shap_means[col_name] = pd.Series(mean_abs_shap, index=feat_names[:len(mean_abs_shap)])\n",
        "\n",
        "                if subgroup_shap_means:\n",
        "                    subgroup_df = pd.DataFrame(subgroup_shap_means)\n",
        "                    subgroup_save_path = os.path.join(io_dir, f'subgroup_mean_abs_shap_{domain}_{target}.csv')\n",
        "                    subgroup_df.to_csv(subgroup_save_path)\n",
        "                    logger.info(f\"Saved subgroup mean absolute SHAP values to {subgroup_save_path}\")\n",
        "                else:\n",
        "                    logger.info(f\"No subgroups met the minimum size requirement or no categorical features were processed successfully for {domain}/{target}. No subgroup analysis CSV saved.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"An unexpected error occurred while processing {domain}/{target}: {e}\", exc_info=True)\n",
        "            continue\n",
        "\n",
        "logger.info(\"Phase 3: Stability & Subgroup Analysis - Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vZOFRySKQYq",
        "outputId": "2f2058c1-dd8d-4602-875f-1f7bef60cd13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-06 20:35:07,449 [INFO] Starting Phase 3: Stability & Subgroup Analysis\n",
            "2025-07-06 20:35:07,453 [INFO] Processing classification/HumanCharacterization\n",
            "2025-07-06 20:35:07,477 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_XGBoost_GridCV_HumanCharacterization.joblib\n",
            "2025-07-06 20:35:07,508 [INFO] Starting bootstrap stability analysis for classification/HumanCharacterization with 100 samples.\n",
            "2025-07-06 20:38:29,769 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/classification/HumanCharacterization/mean_bootstrap_rho_classification_HumanCharacterization.csv\n",
            "2025-07-06 20:38:29,777 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/classification/HumanCharacterization/bootstrap_stability_features_classification_HumanCharacterization.csv\n",
            "2025-07-06 20:38:29,778 [INFO] Starting subgroup analysis for classification/HumanCharacterization.\n",
            "2025-07-06 20:38:29,781 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 325 samples.\n",
            "2025-07-06 20:38:29,785 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 1388 samples.\n",
            "2025-07-06 20:38:29,788 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 1383 samples.\n",
            "2025-07-06 20:38:29,791 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 330 samples.\n",
            "2025-07-06 20:38:29,793 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 1596 samples.\n",
            "2025-07-06 20:38:29,797 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 117 samples.\n",
            "2025-07-06 20:38:29,799 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 1529 samples.\n",
            "2025-07-06 20:38:29,802 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 184 samples.\n",
            "2025-07-06 20:38:29,805 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 1517 samples.\n",
            "2025-07-06 20:38:29,807 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 196 samples.\n",
            "2025-07-06 20:38:29,810 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 1599 samples.\n",
            "2025-07-06 20:38:29,812 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 114 samples.\n",
            "2025-07-06 20:38:29,814 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 1428 samples.\n",
            "2025-07-06 20:38:29,816 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 285 samples.\n",
            "2025-07-06 20:38:29,825 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/classification/HumanCharacterization/subgroup_mean_abs_shap_classification_HumanCharacterization.csv\n",
            "2025-07-06 20:38:29,826 [INFO] Processing classification/MovementTechnique\n",
            "2025-07-06 20:38:29,845 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_XGBoost_GridCV_MovementTechnique.joblib\n",
            "2025-07-06 20:38:29,878 [INFO] Starting bootstrap stability analysis for classification/MovementTechnique with 100 samples.\n",
            "2025-07-06 20:42:25,342 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/classification/MovementTechnique/mean_bootstrap_rho_classification_MovementTechnique.csv\n",
            "2025-07-06 20:42:25,348 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/classification/MovementTechnique/bootstrap_stability_features_classification_MovementTechnique.csv\n",
            "2025-07-06 20:42:25,349 [INFO] Starting subgroup analysis for classification/MovementTechnique.\n",
            "2025-07-06 20:42:25,351 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 1392 samples.\n",
            "2025-07-06 20:42:25,353 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 321 samples.\n",
            "2025-07-06 20:42:25,356 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 1398 samples.\n",
            "2025-07-06 20:42:25,358 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 315 samples.\n",
            "2025-07-06 20:42:25,360 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 1581 samples.\n",
            "2025-07-06 20:42:25,362 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 132 samples.\n",
            "2025-07-06 20:42:25,364 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 1555 samples.\n",
            "2025-07-06 20:42:25,366 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 158 samples.\n",
            "2025-07-06 20:42:25,368 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 1536 samples.\n",
            "2025-07-06 20:42:25,370 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 177 samples.\n",
            "2025-07-06 20:42:25,373 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 1569 samples.\n",
            "2025-07-06 20:42:25,375 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 144 samples.\n",
            "2025-07-06 20:42:25,378 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 1409 samples.\n",
            "2025-07-06 20:42:25,380 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 304 samples.\n",
            "2025-07-06 20:42:25,384 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/classification/MovementTechnique/subgroup_mean_abs_shap_classification_MovementTechnique.csv\n",
            "2025-07-06 20:42:25,385 [INFO] Processing classification/PublicInvolvement\n",
            "2025-07-06 20:42:25,407 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_CatBoost_GridCV_PublicInvolvement.joblib\n",
            "2025-07-06 20:42:25,467 [INFO] Starting bootstrap stability analysis for classification/PublicInvolvement with 100 samples.\n",
            "2025-07-06 20:55:54,898 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/classification/PublicInvolvement/mean_bootstrap_rho_classification_PublicInvolvement.csv\n",
            "2025-07-06 20:55:54,902 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/classification/PublicInvolvement/bootstrap_stability_features_classification_PublicInvolvement.csv\n",
            "2025-07-06 20:55:54,904 [INFO] Starting subgroup analysis for classification/PublicInvolvement.\n",
            "2025-07-06 20:55:54,906 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 1413 samples.\n",
            "2025-07-06 20:55:54,908 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 300 samples.\n",
            "2025-07-06 20:55:54,910 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 1396 samples.\n",
            "2025-07-06 20:55:54,912 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 317 samples.\n",
            "2025-07-06 20:55:54,914 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 1569 samples.\n",
            "2025-07-06 20:55:54,916 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 144 samples.\n",
            "2025-07-06 20:55:54,918 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 1547 samples.\n",
            "2025-07-06 20:55:54,920 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 166 samples.\n",
            "2025-07-06 20:55:54,922 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 203 samples.\n",
            "2025-07-06 20:55:54,924 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 1510 samples.\n",
            "2025-07-06 20:55:54,927 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 1581 samples.\n",
            "2025-07-06 20:55:54,929 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 132 samples.\n",
            "2025-07-06 20:55:54,932 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 1445 samples.\n",
            "2025-07-06 20:55:54,935 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 268 samples.\n",
            "2025-07-06 20:55:54,940 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/classification/PublicInvolvement/subgroup_mean_abs_shap_classification_PublicInvolvement.csv\n",
            "2025-07-06 20:55:54,940 [INFO] Processing classification/SpaceUse\n",
            "2025-07-06 20:55:54,960 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_CatBoost_GridCV_SpaceUse.joblib\n",
            "2025-07-06 20:55:55,005 [INFO] Starting bootstrap stability analysis for classification/SpaceUse with 100 samples.\n",
            "2025-07-06 21:09:28,656 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/classification/SpaceUse/mean_bootstrap_rho_classification_SpaceUse.csv\n",
            "2025-07-06 21:09:28,662 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/classification/SpaceUse/bootstrap_stability_features_classification_SpaceUse.csv\n",
            "2025-07-06 21:09:28,663 [INFO] Starting subgroup analysis for classification/SpaceUse.\n",
            "2025-07-06 21:09:28,666 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 1375 samples.\n",
            "2025-07-06 21:09:28,668 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 338 samples.\n",
            "2025-07-06 21:09:28,672 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 1394 samples.\n",
            "2025-07-06 21:09:28,674 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 319 samples.\n",
            "2025-07-06 21:09:28,676 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 1582 samples.\n",
            "2025-07-06 21:09:28,678 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 131 samples.\n",
            "2025-07-06 21:09:28,680 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 1561 samples.\n",
            "2025-07-06 21:09:28,682 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 152 samples.\n",
            "2025-07-06 21:09:28,685 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 1543 samples.\n",
            "2025-07-06 21:09:28,688 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 170 samples.\n",
            "2025-07-06 21:09:28,690 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 1586 samples.\n",
            "2025-07-06 21:09:28,694 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 127 samples.\n",
            "2025-07-06 21:09:28,698 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 313 samples.\n",
            "2025-07-06 21:09:28,704 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 1400 samples.\n",
            "2025-07-06 21:09:28,709 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/classification/SpaceUse/subgroup_mean_abs_shap_classification_SpaceUse.csv\n",
            "2025-07-06 21:09:28,711 [INFO] Processing classification/Rhythm\n",
            "2025-07-06 21:09:28,748 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_XGBoost_GridCV_Rhythm.joblib\n",
            "2025-07-06 21:09:28,789 [INFO] Starting bootstrap stability analysis for classification/Rhythm with 100 samples.\n",
            "2025-07-06 21:20:35,583 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/classification/Rhythm/mean_bootstrap_rho_classification_Rhythm.csv\n",
            "2025-07-06 21:20:35,589 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/classification/Rhythm/bootstrap_stability_features_classification_Rhythm.csv\n",
            "2025-07-06 21:20:35,590 [INFO] Starting subgroup analysis for classification/Rhythm.\n",
            "2025-07-06 21:20:35,593 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 1427 samples.\n",
            "2025-07-06 21:20:35,595 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 286 samples.\n",
            "2025-07-06 21:20:35,597 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 330 samples.\n",
            "2025-07-06 21:20:35,599 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 1383 samples.\n",
            "2025-07-06 21:20:35,602 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 1593 samples.\n",
            "2025-07-06 21:20:35,604 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 120 samples.\n",
            "2025-07-06 21:20:35,606 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 1525 samples.\n",
            "2025-07-06 21:20:35,608 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 188 samples.\n",
            "2025-07-06 21:20:35,610 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 1520 samples.\n",
            "2025-07-06 21:20:35,612 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 193 samples.\n",
            "2025-07-06 21:20:35,614 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 1578 samples.\n",
            "2025-07-06 21:20:35,616 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 135 samples.\n",
            "2025-07-06 21:20:35,618 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 1423 samples.\n",
            "2025-07-06 21:20:35,620 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 290 samples.\n",
            "2025-07-06 21:20:35,625 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/classification/Rhythm/subgroup_mean_abs_shap_classification_Rhythm.csv\n",
            "2025-07-06 21:20:35,627 [INFO] Processing classification/HumanReproducibility\n",
            "2025-07-06 21:20:35,646 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_CatBoost_GridCV_HumanReproducibility.joblib\n",
            "2025-07-06 21:20:35,667 [INFO] Starting bootstrap stability analysis for classification/HumanReproducibility with 100 samples.\n",
            "2025-07-06 21:24:54,387 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/classification/HumanReproducibility/mean_bootstrap_rho_classification_HumanReproducibility.csv\n",
            "2025-07-06 21:24:54,393 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/classification/HumanReproducibility/bootstrap_stability_features_classification_HumanReproducibility.csv\n",
            "2025-07-06 21:24:54,394 [INFO] Starting subgroup analysis for classification/HumanReproducibility.\n",
            "2025-07-06 21:24:54,398 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 1416 samples.\n",
            "2025-07-06 21:24:54,401 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 297 samples.\n",
            "2025-07-06 21:24:54,403 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 1386 samples.\n",
            "2025-07-06 21:24:54,405 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 327 samples.\n",
            "2025-07-06 21:24:54,408 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 1592 samples.\n",
            "2025-07-06 21:24:54,410 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 121 samples.\n",
            "2025-07-06 21:24:54,413 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 1549 samples.\n",
            "2025-07-06 21:24:54,416 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 164 samples.\n",
            "2025-07-06 21:24:54,419 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 1520 samples.\n",
            "2025-07-06 21:24:54,421 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 193 samples.\n",
            "2025-07-06 21:24:54,424 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 135 samples.\n",
            "2025-07-06 21:24:54,427 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 1578 samples.\n",
            "2025-07-06 21:24:54,430 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 1407 samples.\n",
            "2025-07-06 21:24:54,435 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 306 samples.\n",
            "2025-07-06 21:24:54,442 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/classification/HumanReproducibility/subgroup_mean_abs_shap_classification_HumanReproducibility.csv\n",
            "2025-07-06 21:24:54,445 [INFO] Processing classification/StoryTelling\n",
            "2025-07-06 21:24:54,463 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_XGBoost_GridCV_StoryTelling.joblib\n",
            "2025-07-06 21:24:54,500 [INFO] Starting bootstrap stability analysis for classification/StoryTelling with 100 samples.\n",
            "2025-07-06 21:33:38,956 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/classification/StoryTelling/mean_bootstrap_rho_classification_StoryTelling.csv\n",
            "2025-07-06 21:33:38,963 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/classification/StoryTelling/bootstrap_stability_features_classification_StoryTelling.csv\n",
            "2025-07-06 21:33:38,964 [INFO] Starting subgroup analysis for classification/StoryTelling.\n",
            "2025-07-06 21:33:38,967 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 1400 samples.\n",
            "2025-07-06 21:33:38,970 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 313 samples.\n",
            "2025-07-06 21:33:38,972 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 1410 samples.\n",
            "2025-07-06 21:33:38,974 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 303 samples.\n",
            "2025-07-06 21:33:38,976 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 126 samples.\n",
            "2025-07-06 21:33:38,979 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 1587 samples.\n",
            "2025-07-06 21:33:38,981 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 1565 samples.\n",
            "2025-07-06 21:33:38,983 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 148 samples.\n",
            "2025-07-06 21:33:38,985 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 1513 samples.\n",
            "2025-07-06 21:33:38,987 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 200 samples.\n",
            "2025-07-06 21:33:38,990 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 1569 samples.\n",
            "2025-07-06 21:33:38,992 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 144 samples.\n",
            "2025-07-06 21:33:38,995 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 1407 samples.\n",
            "2025-07-06 21:33:38,997 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 306 samples.\n",
            "2025-07-06 21:33:39,001 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/classification/StoryTelling/subgroup_mean_abs_shap_classification_StoryTelling.csv\n",
            "2025-07-06 21:33:39,003 [INFO] Processing regression/HumanCharacterization\n",
            "2025-07-06 21:33:39,022 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/CatBoost/catboost_humancharacterization.cbm\n",
            "2025-07-06 21:33:39,064 [INFO] Starting bootstrap stability analysis for regression/HumanCharacterization with 100 samples.\n",
            "2025-07-06 21:43:03,675 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/HumanCharacterization/mean_bootstrap_rho_regression_HumanCharacterization.csv\n",
            "2025-07-06 21:43:03,679 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/HumanCharacterization/bootstrap_stability_features_regression_HumanCharacterization.csv\n",
            "2025-07-06 21:43:03,680 [INFO] Starting subgroup analysis for regression/HumanCharacterization.\n",
            "2025-07-06 21:43:03,682 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 710 samples.\n",
            "2025-07-06 21:43:03,684 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 147 samples.\n",
            "2025-07-06 21:43:03,686 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 689 samples.\n",
            "2025-07-06 21:43:03,688 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 168 samples.\n",
            "2025-07-06 21:43:03,690 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 793 samples.\n",
            "2025-07-06 21:43:03,692 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 64 samples.\n",
            "2025-07-06 21:43:03,694 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 775 samples.\n",
            "2025-07-06 21:43:03,695 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 82 samples.\n",
            "2025-07-06 21:43:03,697 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 773 samples.\n",
            "2025-07-06 21:43:03,699 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 84 samples.\n",
            "2025-07-06 21:43:03,701 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 789 samples.\n",
            "2025-07-06 21:43:03,703 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 68 samples.\n",
            "2025-07-06 21:43:03,705 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 145 samples.\n",
            "2025-07-06 21:43:03,707 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 712 samples.\n",
            "2025-07-06 21:43:03,711 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/HumanCharacterization/subgroup_mean_abs_shap_regression_HumanCharacterization.csv\n",
            "2025-07-06 21:43:03,711 [INFO] Processing regression/Storytelling\n",
            "2025-07-06 21:43:03,799 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/XGBoost/xgb_model_storytelling.json\n",
            "2025-07-06 21:43:04,867 [INFO] Starting bootstrap stability analysis for regression/Storytelling with 100 samples.\n",
            "100%|===================| 855/857 [00:17<00:00]       2025-07-06 22:10:51,076 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/Storytelling/mean_bootstrap_rho_regression_Storytelling.csv\n",
            "2025-07-06 22:10:51,081 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/Storytelling/bootstrap_stability_features_regression_Storytelling.csv\n",
            "2025-07-06 22:10:51,081 [INFO] Starting subgroup analysis for regression/Storytelling.\n",
            "2025-07-06 22:10:51,084 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 710 samples.\n",
            "2025-07-06 22:10:51,086 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 147 samples.\n",
            "2025-07-06 22:10:51,088 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 689 samples.\n",
            "2025-07-06 22:10:51,091 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 168 samples.\n",
            "2025-07-06 22:10:51,093 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 793 samples.\n",
            "2025-07-06 22:10:51,095 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 64 samples.\n",
            "2025-07-06 22:10:51,097 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 775 samples.\n",
            "2025-07-06 22:10:51,099 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 82 samples.\n",
            "2025-07-06 22:10:51,101 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 773 samples.\n",
            "2025-07-06 22:10:51,103 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 84 samples.\n",
            "2025-07-06 22:10:51,105 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 789 samples.\n",
            "2025-07-06 22:10:51,108 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 68 samples.\n",
            "2025-07-06 22:10:51,111 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 145 samples.\n",
            "2025-07-06 22:10:51,113 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 712 samples.\n",
            "2025-07-06 22:10:51,118 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/Storytelling/subgroup_mean_abs_shap_regression_Storytelling.csv\n",
            "2025-07-06 22:10:51,119 [INFO] Processing regression/MovementTechnique\n",
            "2025-07-06 22:10:51,214 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/XGBoost/xgb_model_movementtechnique.json\n",
            "2025-07-06 22:10:51,317 [INFO] Starting bootstrap stability analysis for regression/MovementTechnique with 100 samples.\n",
            " 98%|===================| 837/857 [00:17<00:00]       2025-07-06 22:38:26,410 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/MovementTechnique/mean_bootstrap_rho_regression_MovementTechnique.csv\n",
            "2025-07-06 22:38:26,416 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/MovementTechnique/bootstrap_stability_features_regression_MovementTechnique.csv\n",
            "2025-07-06 22:38:26,417 [INFO] Starting subgroup analysis for regression/MovementTechnique.\n",
            "2025-07-06 22:38:26,419 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 710 samples.\n",
            "2025-07-06 22:38:26,421 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 147 samples.\n",
            "2025-07-06 22:38:26,423 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 689 samples.\n",
            "2025-07-06 22:38:26,425 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 168 samples.\n",
            "2025-07-06 22:38:26,426 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 793 samples.\n",
            "2025-07-06 22:38:26,428 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 64 samples.\n",
            "2025-07-06 22:38:26,430 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 775 samples.\n",
            "2025-07-06 22:38:26,432 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 82 samples.\n",
            "2025-07-06 22:38:26,434 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 773 samples.\n",
            "2025-07-06 22:38:26,436 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 84 samples.\n",
            "2025-07-06 22:38:26,438 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 789 samples.\n",
            "2025-07-06 22:38:26,440 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 68 samples.\n",
            "2025-07-06 22:38:26,441 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 145 samples.\n",
            "2025-07-06 22:38:26,443 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 712 samples.\n",
            "2025-07-06 22:38:26,448 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/MovementTechnique/subgroup_mean_abs_shap_regression_MovementTechnique.csv\n",
            "2025-07-06 22:38:26,449 [INFO] Processing regression/PublicInvolvement\n",
            "2025-07-06 22:38:26,501 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/XGBoost/xgb_model_publicinvolvement.json\n",
            "2025-07-06 22:38:26,586 [INFO] Starting bootstrap stability analysis for regression/PublicInvolvement with 100 samples.\n",
            "2025-07-06 22:50:39,349 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/PublicInvolvement/mean_bootstrap_rho_regression_PublicInvolvement.csv\n",
            "2025-07-06 22:50:39,356 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/PublicInvolvement/bootstrap_stability_features_regression_PublicInvolvement.csv\n",
            "2025-07-06 22:50:39,357 [INFO] Starting subgroup analysis for regression/PublicInvolvement.\n",
            "2025-07-06 22:50:39,360 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 710 samples.\n",
            "2025-07-06 22:50:39,362 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 147 samples.\n",
            "2025-07-06 22:50:39,364 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 689 samples.\n",
            "2025-07-06 22:50:39,366 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 168 samples.\n",
            "2025-07-06 22:50:39,368 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 793 samples.\n",
            "2025-07-06 22:50:39,370 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 64 samples.\n",
            "2025-07-06 22:50:39,372 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 775 samples.\n",
            "2025-07-06 22:50:39,374 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 82 samples.\n",
            "2025-07-06 22:50:39,377 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 773 samples.\n",
            "2025-07-06 22:50:39,379 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 84 samples.\n",
            "2025-07-06 22:50:39,381 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 789 samples.\n",
            "2025-07-06 22:50:39,382 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 68 samples.\n",
            "2025-07-06 22:50:39,384 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 145 samples.\n",
            "2025-07-06 22:50:39,386 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 712 samples.\n",
            "2025-07-06 22:50:39,391 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/PublicInvolvement/subgroup_mean_abs_shap_regression_PublicInvolvement.csv\n",
            "2025-07-06 22:50:39,393 [INFO] Processing regression/SpaceUse\n",
            "2025-07-06 22:50:39,418 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/XGBoost/xgb_model_spaceuse.json\n",
            "2025-07-06 22:50:39,445 [INFO] Starting bootstrap stability analysis for regression/SpaceUse with 100 samples.\n",
            "2025-07-06 22:52:33,472 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/SpaceUse/mean_bootstrap_rho_regression_SpaceUse.csv\n",
            "2025-07-06 22:52:33,477 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/SpaceUse/bootstrap_stability_features_regression_SpaceUse.csv\n",
            "2025-07-06 22:52:33,478 [INFO] Starting subgroup analysis for regression/SpaceUse.\n",
            "2025-07-06 22:52:33,480 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 710 samples.\n",
            "2025-07-06 22:52:33,482 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 147 samples.\n",
            "2025-07-06 22:52:33,484 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 689 samples.\n",
            "2025-07-06 22:52:33,486 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 168 samples.\n",
            "2025-07-06 22:52:33,488 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 793 samples.\n",
            "2025-07-06 22:52:33,490 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 64 samples.\n",
            "2025-07-06 22:52:33,492 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 775 samples.\n",
            "2025-07-06 22:52:33,493 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 82 samples.\n",
            "2025-07-06 22:52:33,495 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 773 samples.\n",
            "2025-07-06 22:52:33,497 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 84 samples.\n",
            "2025-07-06 22:52:33,499 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 789 samples.\n",
            "2025-07-06 22:52:33,501 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 68 samples.\n",
            "2025-07-06 22:52:33,504 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 145 samples.\n",
            "2025-07-06 22:52:33,505 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 712 samples.\n",
            "2025-07-06 22:52:33,509 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/SpaceUse/subgroup_mean_abs_shap_regression_SpaceUse.csv\n",
            "2025-07-06 22:52:33,510 [INFO] Processing regression/Rhythm\n",
            "2025-07-06 22:52:33,527 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/CatBoost/catboost_rhythm.cbm\n",
            "2025-07-06 22:52:33,564 [INFO] Starting bootstrap stability analysis for regression/Rhythm with 100 samples.\n",
            "2025-07-06 22:59:16,111 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/Rhythm/mean_bootstrap_rho_regression_Rhythm.csv\n",
            "2025-07-06 22:59:16,121 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/Rhythm/bootstrap_stability_features_regression_Rhythm.csv\n",
            "2025-07-06 22:59:16,122 [INFO] Starting subgroup analysis for regression/Rhythm.\n",
            "2025-07-06 22:59:16,126 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 710 samples.\n",
            "2025-07-06 22:59:16,130 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 147 samples.\n",
            "2025-07-06 22:59:16,133 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 689 samples.\n",
            "2025-07-06 22:59:16,138 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 168 samples.\n",
            "2025-07-06 22:59:16,141 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 793 samples.\n",
            "2025-07-06 22:59:16,144 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 64 samples.\n",
            "2025-07-06 22:59:16,148 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 775 samples.\n",
            "2025-07-06 22:59:16,150 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 82 samples.\n",
            "2025-07-06 22:59:16,154 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 773 samples.\n",
            "2025-07-06 22:59:16,157 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 84 samples.\n",
            "2025-07-06 22:59:16,160 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 789 samples.\n",
            "2025-07-06 22:59:16,162 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 68 samples.\n",
            "2025-07-06 22:59:16,164 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 145 samples.\n",
            "2025-07-06 22:59:16,165 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 712 samples.\n",
            "2025-07-06 22:59:16,173 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/Rhythm/subgroup_mean_abs_shap_regression_Rhythm.csv\n",
            "2025-07-06 22:59:16,174 [INFO] Processing regression/HumanReproducibility\n",
            "2025-07-06 22:59:16,243 [INFO] Loaded model from /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/XGBoost/xgb_model_humanreproducibility.json\n",
            "2025-07-06 22:59:16,316 [INFO] Starting bootstrap stability analysis for regression/HumanReproducibility with 100 samples.\n",
            "2025-07-06 23:07:21,991 [INFO] Saved mean bootstrap rho (stability) per feature to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/HumanReproducibility/mean_bootstrap_rho_regression_HumanReproducibility.csv\n",
            "2025-07-06 23:07:21,996 [INFO] Saved feature-feature bootstrap correlation matrix to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/HumanReproducibility/bootstrap_stability_features_regression_HumanReproducibility.csv\n",
            "2025-07-06 23:07:21,997 [INFO] Starting subgroup analysis for regression/HumanReproducibility.\n",
            "2025-07-06 23:07:21,998 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 0 with 710 samples.\n",
            "2025-07-06 23:07:22,000 [INFO] Analyzing subgroups for feature: musicGenre_electronic - Category: 1 with 147 samples.\n",
            "2025-07-06 23:07:22,005 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 0 with 689 samples.\n",
            "2025-07-06 23:07:22,007 [INFO] Analyzing subgroups for feature: musicGenre_folk - Category: 1 with 168 samples.\n",
            "2025-07-06 23:07:22,009 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 0 with 793 samples.\n",
            "2025-07-06 23:07:22,010 [INFO] Analyzing subgroups for feature: musicGenre_indie - Category: 1 with 64 samples.\n",
            "2025-07-06 23:07:22,012 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 0 with 775 samples.\n",
            "2025-07-06 23:07:22,017 [INFO] Analyzing subgroups for feature: musicGenre_latin - Category: 1 with 82 samples.\n",
            "2025-07-06 23:07:22,021 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 0 with 773 samples.\n",
            "2025-07-06 23:07:22,023 [INFO] Analyzing subgroups for feature: musicGenre_pop - Category: 1 with 84 samples.\n",
            "2025-07-06 23:07:22,025 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 0 with 789 samples.\n",
            "2025-07-06 23:07:22,028 [INFO] Analyzing subgroups for feature: musicGenre_rap - Category: 1 with 68 samples.\n",
            "2025-07-06 23:07:22,030 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 1 with 145 samples.\n",
            "2025-07-06 23:07:22,032 [INFO] Analyzing subgroups for feature: musicGenre_rock - Category: 0 with 712 samples.\n",
            "2025-07-06 23:07:22,036 [INFO] Saved subgroup mean absolute SHAP values to /content/Evaluations_on_Robotic_Choreographies/shap/regression/result/HumanReproducibility/subgroup_mean_abs_shap_regression_HumanReproducibility.csv\n",
            "2025-07-06 23:07:22,038 [INFO] Phase 3: Stability & Subgroup Analysis - Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "phase 4"
      ],
      "metadata": {
        "id": "fgyKYP_PT9Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import logging\n",
        "import joblib\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "from types import SimpleNamespace\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# --- Setup Logging ---\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Configuration (Load from settings.yaml) ---\n",
        "class Settings:\n",
        "    def __init__(self, config_file='settings.yaml'):\n",
        "        try:\n",
        "            with open(config_file, 'r') as f:\n",
        "                settings_data = yaml.safe_load(f)\n",
        "        except FileNotFoundError:\n",
        "            logger.error(f\"Configuration file '{config_file}' not found. Please ensure it's in the current directory.\")\n",
        "            exit(1)\n",
        "\n",
        "        self.random_seed = settings_data.get('random_seed', 42)\n",
        "        self.background = self._get_nested_setting(settings_data, 'background', {'min_size': 100})\n",
        "        self.prototypes = self._get_nested_setting(settings_data, 'prototypes', {'n_high': 1, 'n_low': 1})\n",
        "        self.report = self._get_nested_setting(settings_data, 'report', {'stability_rho_threshold': 0.8})\n",
        "\n",
        "    def _get_nested_setting(self, data, key, default):\n",
        "        cfg = default.copy()\n",
        "        if key in data and isinstance(data[key], dict):\n",
        "            cfg.update(data[key])\n",
        "        return SimpleNamespace(**cfg)\n",
        "\n",
        "settings = Settings()\n",
        "\n",
        "# --- Global Paths ---\n",
        "PROJECT_ROOT = \"/content/Evaluations_on_Robotic_Choreographies/\"\n",
        "BASE_SHAP_DIR = os.path.join(PROJECT_ROOT, \"shap\")\n",
        "BASE_PLOTS_DIR = os.path.join(PROJECT_ROOT, \"plots\")\n",
        "BASE_REPORTS_DIR = os.path.join(PROJECT_ROOT, \"reports\")\n",
        "\n",
        "os.makedirs(BASE_PLOTS_DIR, exist_ok=True)\n",
        "os.makedirs(BASE_REPORTS_DIR, exist_ok=True)\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def unwrap_pipeline(model):\n",
        "    \"\"\"Utility to get the final estimator and preprocessor from a scikit-learn pipeline.\"\"\"\n",
        "    preproc = None\n",
        "    actual_model = model\n",
        "    if isinstance(model, Pipeline):\n",
        "        actual_model = model.steps[-1][1]\n",
        "        if len(model.steps) > 1:\n",
        "            preproc = Pipeline(model.steps[:-1])\n",
        "    return actual_model, preproc\n",
        "\n",
        "def load_model_intelligently(model_path, domain):\n",
        "    \"\"\"Loads a model based on its file extension.\"\"\"\n",
        "    if not os.path.exists(model_path):\n",
        "        logger.error(f\"Model file not found: {model_path}\")\n",
        "        return None\n",
        "\n",
        "    logger.info(f\"Loading model from: {model_path}\")\n",
        "    if model_path.endswith((\".pkl\", \".joblib\")):\n",
        "        return joblib.load(model_path)\n",
        "    elif model_path.endswith(\".cbm\"):\n",
        "        if domain == 'classification':\n",
        "            model = CatBoostClassifier()\n",
        "        else:\n",
        "            model = CatBoostRegressor()\n",
        "        model.load_model(model_path)\n",
        "        return model\n",
        "    elif model_path.endswith(\".json\"):\n",
        "        if domain == 'classification':\n",
        "            model = xgb.XGBClassifier()\n",
        "        else:\n",
        "            model = xgb.XGBRegressor()\n",
        "        model.load_model(model_path)\n",
        "        return model\n",
        "    else:\n",
        "        logger.error(f\"Unsupported model file extension for: {model_path}\")\n",
        "        return None\n",
        "\n",
        "def get_explainer_and_data(config_path):\n",
        "    \"\"\"Loads explainer, model, and data based on the config.\"\"\"\n",
        "    try:\n",
        "        with open(config_path, 'r') as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        # Correctly determine domain from path\n",
        "        io_dir = os.path.dirname(config_path)\n",
        "        domain_dir = os.path.dirname(io_dir)\n",
        "        if os.path.basename(domain_dir) == 'result': # Handle regression's nested structure\n",
        "            domain_dir = os.path.dirname(domain_dir)\n",
        "        domain = os.path.basename(domain_dir)\n",
        "\n",
        "        # Load essential components\n",
        "        model_path = config[\"model_path\"]\n",
        "        background_path = config[\"background_path\"]\n",
        "        eval_data_path = config[\"eval_data_path\"]\n",
        "        feature_names_path = config[\"feature_names_path\"]\n",
        "\n",
        "        # Use the intelligent loader\n",
        "        model = load_model_intelligently(model_path, domain)\n",
        "        if model is None: return None, None, None, None, None\n",
        "\n",
        "        actual_model, preproc = unwrap_pipeline(model)\n",
        "\n",
        "        background_data = pd.read_csv(background_path)\n",
        "        X_eval_raw = pd.read_csv(eval_data_path)\n",
        "\n",
        "        with open(feature_names_path, 'r') as f:\n",
        "            feature_names = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "        # Apply preprocessing if it exists\n",
        "        if preproc:\n",
        "            X_eval_proc = pd.DataFrame(preproc.transform(X_eval_raw), columns=feature_names, index=X_eval_raw.index)\n",
        "        else:\n",
        "            X_eval_proc = X_eval_raw.copy()\n",
        "            X_eval_proc.columns = feature_names\n",
        "\n",
        "        # Instantiate explainer with the ACTUAL model\n",
        "        explainer = shap.TreeExplainer(actual_model, background_data)\n",
        "\n",
        "        return explainer, actual_model, X_eval_proc, feature_names, domain\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load components for {config_path}: {e}\", exc_info=True)\n",
        "        return None, None, None, None, None\n",
        "\n",
        "# --- Main Phase 4 Execution ---\n",
        "def run_phase4():\n",
        "    logger.info(\"Starting Phase 4: Synthesize the Narrative\")\n",
        "\n",
        "    # --- 2. Prototypical Decision Plots ---\n",
        "    logger.info(\"Generating Prototypical Decision Plots.\")\n",
        "    all_config_files = glob.glob(os.path.join(BASE_SHAP_DIR, \"**\", \"config.json\"), recursive=True)\n",
        "\n",
        "    for config_path in all_config_files:\n",
        "        try:\n",
        "            explainer, model, X_proc, feature_names, domain = get_explainer_and_data(config_path)\n",
        "            if not all([explainer, model, X_proc is not None, feature_names]):\n",
        "                logger.warning(f\"Skipping decision plots for {config_path} due to loading errors.\")\n",
        "                continue\n",
        "\n",
        "            io_dir = os.path.dirname(config_path)\n",
        "            target = os.path.basename(io_dir)\n",
        "            model_filename = os.path.basename(json.load(open(config_path))[\"model_path\"])\n",
        "            method = model_filename.split('_')[2] if 'OVERALL_BEST' in model_filename else model_filename.split('_')[0]\n",
        "\n",
        "            raw_shap_path = json.load(open(config_path))[\"raw_shap_path\"]\n",
        "            shap_vals = np.load(raw_shap_path, allow_pickle=True)\n",
        "\n",
        "            # For classification, SHAP values can be a list of arrays. We typically want the one for the positive class.\n",
        "            shap_vals_for_plot = shap_vals[1] if isinstance(shap_vals, list) else shap_vals\n",
        "\n",
        "            # Get model predictions to find high/low cases\n",
        "            # NO MORE DMatrix. The sklearn wrappers handle it.\n",
        "            if domain == 'classification':\n",
        "                predictions = model.predict_proba(X_proc)[:, 1] # Probability of positive class\n",
        "            else: # Regression\n",
        "                predictions = model.predict(X_proc)\n",
        "\n",
        "            sorted_indices = np.argsort(predictions)\n",
        "            high_indices = sorted_indices[-settings.prototypes.n_high:]\n",
        "            low_indices = sorted_indices[:settings.prototypes.n_low]\n",
        "\n",
        "            expected_value = explainer.expected_value\n",
        "            # Handle case where expected_value is a list (for classification)\n",
        "            if isinstance(expected_value, (list, np.ndarray)) and len(expected_value) > 1:\n",
        "                expected_value = expected_value[1]\n",
        "\n",
        "            # Generate and save plots\n",
        "            for i, idx in enumerate(high_indices):\n",
        "                plot_path = os.path.join(BASE_PLOTS_DIR, f\"decision_{method}_{target}_high_{i+1}.png\")\n",
        "                shap.decision_plot(expected_value, shap_vals_for_plot[idx], X_proc.iloc[[idx]], show=False)\n",
        "                plt.savefig(plot_path, bbox_inches='tight')\n",
        "                plt.close()\n",
        "\n",
        "            for i, idx in enumerate(low_indices):\n",
        "                plot_path = os.path.join(BASE_PLOTS_DIR, f\"decision_{method}_{target}_low_{i+1}.png\")\n",
        "                shap.decision_plot(expected_value, shap_vals_for_plot[idx], X_proc.iloc[[idx]], show=False)\n",
        "                plt.savefig(plot_path, bbox_inches='tight')\n",
        "                plt.close()\n",
        "\n",
        "            logger.info(f\"Generated decision plots for {method}-{target}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating decision plots for {config_path}: {e}\", exc_info=True)\n",
        "            continue\n",
        "\n",
        "    logger.info(\"Phase 4: Synthesize the Narrative - Complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    plt.ioff()\n",
        "    run_phase4()\n",
        "\n"
      ],
      "metadata": {
        "id": "IItl6uI0KQWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea8e0e6-d107-48e0-dcc1-54860398ed6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-06 23:07:22,137 [INFO] Starting Phase 4: Synthesize the Narrative\n",
            "2025-07-06 23:07:22,138 [INFO] Generating Prototypical Decision Plots.\n",
            "2025-07-06 23:07:22,143 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/CatBoost/catboost_humancharacterization.cbm\n",
            "2025-07-06 23:07:23,358 [INFO] Generated decision plots for catboost-HumanCharacterization\n",
            "2025-07-06 23:07:23,359 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/XGBoost/xgb_model_storytelling.json\n",
            "2025-07-06 23:07:24,459 [INFO] Generated decision plots for xgb-Storytelling\n",
            "2025-07-06 23:07:24,460 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/XGBoost/xgb_model_movementtechnique.json\n",
            "2025-07-06 23:07:25,820 [INFO] Generated decision plots for xgb-MovementTechnique\n",
            "2025-07-06 23:07:25,821 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/XGBoost/xgb_model_publicinvolvement.json\n",
            "2025-07-06 23:07:26,688 [INFO] Generated decision plots for xgb-PublicInvolvement\n",
            "2025-07-06 23:07:26,689 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/XGBoost/xgb_model_spaceuse.json\n",
            "2025-07-06 23:07:27,493 [INFO] Generated decision plots for xgb-SpaceUse\n",
            "2025-07-06 23:07:27,494 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/CatBoost/catboost_rhythm.cbm\n",
            "2025-07-06 23:07:28,247 [INFO] Generated decision plots for catboost-Rhythm\n",
            "2025-07-06 23:07:28,248 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/regression/Tuned Models/XGBoost/xgb_model_humanreproducibility.json\n",
            "2025-07-06 23:07:29,035 [INFO] Generated decision plots for xgb-HumanReproducibility\n",
            "2025-07-06 23:07:29,036 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_XGBoost_GridCV_HumanCharacterization.joblib\n",
            "2025-07-06 23:07:29,795 [INFO] Generated decision plots for XGBoost-HumanCharacterization\n",
            "2025-07-06 23:07:29,796 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_XGBoost_GridCV_MovementTechnique.joblib\n",
            "2025-07-06 23:07:30,549 [INFO] Generated decision plots for XGBoost-MovementTechnique\n",
            "2025-07-06 23:07:30,550 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_CatBoost_GridCV_PublicInvolvement.joblib\n",
            "2025-07-06 23:07:31,330 [INFO] Generated decision plots for CatBoost-PublicInvolvement\n",
            "2025-07-06 23:07:31,331 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_CatBoost_GridCV_SpaceUse.joblib\n",
            "2025-07-06 23:07:32,561 [INFO] Generated decision plots for CatBoost-SpaceUse\n",
            "2025-07-06 23:07:32,563 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_XGBoost_GridCV_Rhythm.joblib\n",
            "2025-07-06 23:07:33,321 [INFO] Generated decision plots for XGBoost-Rhythm\n",
            "2025-07-06 23:07:33,322 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_CatBoost_GridCV_HumanReproducibility.joblib\n",
            "2025-07-06 23:07:34,229 [INFO] Generated decision plots for CatBoost-HumanReproducibility\n",
            "2025-07-06 23:07:34,230 [INFO] Loading model from: /content/Evaluations_on_Robotic_Choreographies/classification/saved_overall_best_models/OVERALL_BEST_XGBoost_GridCV_StoryTelling.joblib\n",
            "2025-07-06 23:07:35,356 [INFO] Generated decision plots for XGBoost-StoryTelling\n",
            "2025-07-06 23:07:35,357 [INFO] Phase 4: Synthesize the Narrative - Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "import yaml\n",
        "\n",
        "# --- Setup Logging ---\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Load Settings ---\n",
        "def load_settings(config_file='settings.yaml'):\n",
        "    try:\n",
        "        with open(config_file, 'r') as f:\n",
        "            data = yaml.safe_load(f)\n",
        "    except FileNotFoundError:\n",
        "        logger.error(f\"Settings file '{config_file}' not found.\")\n",
        "        raise\n",
        "    return data\n",
        "\n",
        "# --- Compute mean absolute SHAP values ---\n",
        "def compute_mean_abs_shap(shap_values, feature_names):\n",
        "    if isinstance(shap_values, list):\n",
        "        arr = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n",
        "    else:\n",
        "        arr = shap_values\n",
        "    arr = np.asarray(arr)\n",
        "    if arr.ndim != 2:\n",
        "        logger.error(f\"Expected 2D SHAP array, got shape {arr.shape}\")\n",
        "        return pd.Series([], dtype=float)\n",
        "    # align feature names\n",
        "    if arr.shape[1] != len(feature_names):\n",
        "        n = min(arr.shape[1], len(feature_names))\n",
        "        feature_names = feature_names[:n]\n",
        "        arr = arr[:, :n]\n",
        "    mean_abs = np.abs(arr).mean(axis=0)\n",
        "    return pd.Series(mean_abs, index=feature_names)\n",
        "\n",
        "# --- Generate Combined Markdown Snippet ---\n",
        "def generate_combined_snippet(df_summary, out_file):\n",
        "    os.makedirs(os.path.dirname(out_file) or '.', exist_ok=True)\n",
        "    with open(out_file, 'w') as f:\n",
        "        f.write(f\"# Automated SHAP Report Snippets\\n\\n\")\n",
        "        f.write(\"This document synthesizes the top features across all methods and targets.\\n\\n---\\n\\n\")\n",
        "        for (method, target), group in df_summary.groupby(['method', 'target']):\n",
        "            f.write(f\"## {method} on {target}\\n\\n\")\n",
        "            f.write(\"**Key Findings**\\n\\n\")\n",
        "            top_feats = group.nlargest(3, 'mean_shap')\n",
        "            for _, row in top_feats.iterrows():\n",
        "                f.write(f\"- **{row['feature']}**: mean SHAP = {row['mean_shap']:.4f}\\n\")\n",
        "            f.write(\"\\n---\\n\\n\")\n",
        "    logger.info(f\"Combined snippet written to {out_file}\")\n",
        "\n",
        "# --- Main Execution ---\n",
        "def run_phase4_summary(shap_root='shap', output_csv='final_summary.csv', snippet_file='report_snippets.md'):\n",
        "    entries = []\n",
        "    # scan for configs\n",
        "    for root, _, files in os.walk(shap_root):\n",
        "        if 'config.json' not in files:\n",
        "            continue\n",
        "        cfg_path = os.path.join(root, 'config.json')\n",
        "        try:\n",
        "            with open(cfg_path, 'r') as f:\n",
        "                cfg = json.load(f)\n",
        "            # derive domain/target\n",
        "            rel = os.path.relpath(root, shap_root).split(os.sep)\n",
        "            if rel[0] == 'regression' and rel[1] == 'result':\n",
        "                domain, target = rel[0], rel[2]\n",
        "            else:\n",
        "                domain, target = rel[0], rel[1]\n",
        "            # method\n",
        "            model_file = os.path.basename(cfg.get('model_path',''))\n",
        "            method = os.path.splitext(model_file)[0]\n",
        "            # load names & values\n",
        "            fn_path = cfg.get('feature_names_path')\n",
        "            raw_path = cfg.get('raw_shap_path')\n",
        "            if not os.path.exists(fn_path) or not os.path.exists(raw_path):\n",
        "                logger.error(f\"Missing files for {method}-{target}\")\n",
        "                continue\n",
        "            feature_names = [ln.strip() for ln in open(fn_path) if ln.strip()]\n",
        "            shap_vals = np.load(raw_path, allow_pickle=True)\n",
        "            mean_shap = compute_mean_abs_shap(shap_vals, feature_names)\n",
        "            for feat, val in mean_shap.items():\n",
        "                entries.append({\n",
        "                    'method': method,\n",
        "                    'target': target,\n",
        "                    'feature': feat,\n",
        "                    'mean_shap': val\n",
        "                })\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error at {cfg_path}: {e}\")\n",
        "            continue\n",
        "    if not entries:\n",
        "        logger.warning(\"No summary entries found.\")\n",
        "        return\n",
        "    # assemble DataFrame\n",
        "    df = pd.DataFrame(entries)\n",
        "    df = df.sort_values(['method','target','mean_shap'], ascending=[True, True, False])\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    logger.info(f\"Final summary CSV: {output_csv}\")\n",
        "    # generate combined markdown snippet\n",
        "    generate_combined_snippet(df, snippet_file)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    settings = load_settings()\n",
        "    shap_root = \"/content/Evaluations_on_Robotic_Choreographies/shap\"\n",
        "    output_csv = settings.get('final_summary_file','final_summary.csv')\n",
        "    snippet_file = settings.get('snippet_file','report_snippets.md')\n",
        "    run_phase4_summary(shap_root, output_csv, snippet_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJZa8NZfcXmo",
        "outputId": "65ebb1ad-3db1-494d-9390-cfd1ee54efd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-06 23:07:35,447 [INFO] Final summary CSV: final_summary.csv\n",
            "2025-07-06 23:07:35,480 [INFO] Combined snippet written to report_snippets.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from zipfile import ZipFile, ZIP_DEFLATED\n",
        "from google.colab import files\n",
        "\n",
        "def zip_folder_zipfile(folder_path, output_zip_path):\n",
        "    \"\"\"\n",
        "    Zips folder_path (including its contents) into output_zip_path.\n",
        "    Preserves directory structure.\n",
        "    \"\"\"\n",
        "    with ZipFile(output_zip_path, 'w', compression=ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                full_path = os.path.join(root, file)\n",
        "                # Store paths relative to the root folder\n",
        "                rel_path = os.path.relpath(full_path, start=os.path.dirname(folder_path))\n",
        "                zipf.write(full_path, arcname=rel_path)\n",
        "    print(f\"Created: {output_zip_path}\")\n",
        "zip_folder_zipfile('/content/Evaluations_on_Robotic_Choreographies/shap', '/content/shap.zip')\n",
        "\n",
        "# Replace 'your_file.zip' with the actual name of your zip file\n",
        "files.download('/content/shap.zip')"
      ],
      "metadata": {
        "id": "S6dknvxWKQT3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d01d4ab6-20f1-4fc1-e777-ccd14b9e0939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created: /content/shap.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b84f80d0-cdc5-4e32-ad31-4bbd5ed62ae5\", \"shap.zip\", 17762220)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
